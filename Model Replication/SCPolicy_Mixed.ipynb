{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPolicy_Mixed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9kxq01msMg9"
      },
      "source": [
        " ### BEWARE:Tensorflow is stochastic - this means the model will not be replicated exactly. \n",
        "### Use GA_Load_Model for reproduction\n",
        "\n",
        "#!pip install mlxtend\n",
        "\n",
        "#!pip install h5py pyyaml\n",
        "\n",
        "#!pip install tensorboard\n",
        "\n",
        "#!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLftnb5sBe7B"
      },
      "source": [
        "#Load packages\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBsKz40OAGDU"
      },
      "source": [
        "### Packages necessary for model construction \n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.callbacks\n",
        "import datetime \n",
        "import statistics\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os \n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn\n",
        "\n",
        "import pydot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrEcBaVWVVkb"
      },
      "source": [
        "#Read the Data\n",
        "\n",
        "UN_Data = pd.read_csv('SC_Query_LIWC.csv')\n",
        "\n",
        "UN_Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUqnWTFS4y2"
      },
      "source": [
        "#Inspect and Clean the Data\n",
        "\n",
        "UN_Data.head(5)\n",
        "\n",
        "UN_Data.drop(['Unnamed: 0'], axis = 1, inplace= True)\n",
        "\n",
        "UN_Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxcCMRKAAZ8Z"
      },
      "source": [
        "#Balance Policy Passage\n",
        "\n",
        "# Count samples per class\n",
        "classes_zero = UN_Data[UN_Data['Policy Passed'] == 0]\n",
        "classes_one = UN_Data[UN_Data['Policy Passed'] == 1]\n",
        "\n",
        "# Convert parts into NumPy arrays for weight computation\n",
        "zero_numpy = classes_zero['Policy Passed'].to_numpy()\n",
        "one_numpy = classes_one['Policy Passed'].to_numpy()\n",
        "all_together = np.concatenate((zero_numpy, one_numpy))\n",
        "unique_classes = np.unique(all_together)\n",
        "\n",
        "# Compute weights\n",
        "weights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)\n",
        "weights = dict(enumerate(weights))\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkn1c4RqeEdO"
      },
      "source": [
        "#Inspect the data by key descriptive statistics\n",
        "\n",
        "UN_Data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c56fLBjJKA3"
      },
      "source": [
        "#Group the data by our label (dependent variable) of policy passage\n",
        "\n",
        "UN_Data.groupby(['Policy Passed']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUEe-fLzAZ8a"
      },
      "source": [
        "#Normalize the data \n",
        "\n",
        "UN_Data1 = tf.keras.utils.normalize(UN_Data.drop(columns = ['Policy Passed']))\n",
        "\n",
        "UN_Data1[\"Policy Passed\"] = UN_Data['Policy Passed']\n",
        "\n",
        "UN_Data1.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6BF8hmXGEnF"
      },
      "source": [
        "#Divide our variables between the independent variables (features) and dependent variables (policy passage)\n",
        "\n",
        "labels = UN_Data1 ['Policy Passed']\n",
        "features = UN_Data1.drop(columns= ['Policy Passed','Conflict Indicator'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWD_YiigAZ8a"
      },
      "source": [
        "#Drop Null Values\n",
        "\n",
        "features = features.fillna(0)\n",
        "labels = labels.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJRWpUNH8Dk"
      },
      "source": [
        "#Inspect shape of features\n",
        "\n",
        "features = pd.get_dummies(features)\n",
        "features.shape[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oGgPi4CG0xx"
      },
      "source": [
        "#Define type of feature and label values\n",
        "\n",
        "features = features.values.astype('float32')\n",
        "labels = labels.values.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOea_aP_HPSE"
      },
      "source": [
        "#Data Sets for Training\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)\n",
        "features_train, features_validation, labels_train, labels_validation = train_test_split(features_train, labels_train, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSYOIsh5vq4"
      },
      "source": [
        "#Define Precision, Recall, and F1 score metrics\n",
        "import keras.backend as K\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall_keras\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    weights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VQ_OqkCHkLM"
      },
      "source": [
        "#Create your model\n",
        "\n",
        "model1 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model2 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model3 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model4 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model5 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model6 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model7 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model8 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model9 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model10 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model11 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model12 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model13 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model14 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model15 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model16 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model17 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model18 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model19 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model20 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model21 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model22 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model23 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model24 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model25 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model26 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model27 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model28 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model29 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model30 = tf.keras.Sequential([keras.layers.Dense(126, input_shape=(98,)),keras.layers.Dropout(.20),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.15),keras.layers.Dense(32, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0rVTIUthFzi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JTlq8aH8mzi"
      },
      "source": [
        "### Inspect form of model\n",
        "\n",
        "tf.keras.utils.plot_model(model1, to_file='model.png', show_shapes = True, show_dtype=True, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Vb8b-qSIQ4"
      },
      "source": [
        "#Check Trainable Parameters\n",
        "# Note: All the models are similarly structured\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyx2tehuTPfe"
      },
      "source": [
        "#Set checkpoints, metrics, loss, and optimizer functions for the model\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model7.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model8.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model9.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model10.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model11.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model12.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model13.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model14.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model15.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model16.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model17.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model18.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model19.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model20.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model21.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model22.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model23.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model24.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model25.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model26.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model27.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model28.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model29.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model30.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhwA7DthFS72"
      },
      "source": [
        "#Run the model\n",
        "\n",
        "print(\"Model 1 Fitting\")\n",
        "history1 = model1.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 2 Fitting\")\n",
        "history2 = model2.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 3 Fitting\")\n",
        "history3 = model3.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 4 Fitting\")\n",
        "history4 = model4.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 5 Fitting\")\n",
        "history5 = model5.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 6 Fitting\")\n",
        "history6 = model6.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 7 Fitting\")\n",
        "history7 = model7.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 8 Fitting\")\n",
        "history8 = model8.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 9 Fitting\")\n",
        "history9 = model9.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 10 Fitting\")\n",
        "history10 = model10.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 11 Fitting\")\n",
        "history11 = model11.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 12 Fitting\")\n",
        "history12 = model12.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 13 Fitting\")\n",
        "history13 = model13.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 14 Fitting\")\n",
        "history14 = model14.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 15 Fitting\")\n",
        "history15 = model15.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 16 Fitting\")\n",
        "history16 = model16.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 17 Fitting\")\n",
        "history17 = model17.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 18 Fitting\")\n",
        "history18 = model18.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 19 Fitting\")\n",
        "history19 = model19.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 20 Fitting\")\n",
        "history20 = model20.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 21 Fitting\")\n",
        "history21 = model21.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 22 Fitting\")\n",
        "history22 = model22.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 23 Fitting\")\n",
        "history23 = model23.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 24 Fitting\")\n",
        "history24 = model24.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 25 Fitting\")\n",
        "history25 = model25.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 26 Fitting\")\n",
        "history26 = model26.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 27 Fitting\")\n",
        "history27 = model27.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 28 Fitting\")\n",
        "history28 = model28.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 29 Fitting\")\n",
        "history29 = model29.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 30 Fitting\")\n",
        "history30 = model30.fit(features_train, labels_train, epochs=50, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfHp9ww0FWvB"
      },
      "source": [
        "#Run model predictions\n",
        "\n",
        "# Model 1 \n",
        "prediction_features_1 = model1.predict(features_test)\n",
        "performance1 = model1.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 2 \n",
        "prediction_features_2 = model2.predict(features_test)\n",
        "performance2 = model2.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 3 \n",
        "prediction_features_3 = model3.predict(features_test)\n",
        "performance3 = model3.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 4 \n",
        "prediction_features_4 = model4.predict(features_test)\n",
        "performance4 = model4.evaluate(features_test, labels_test)\n",
        "print(performance4)\n",
        "# Model 5 \n",
        "prediction_features_5 = model5.predict(features_test)\n",
        "performance5 = model5.evaluate(features_test, labels_test)\n",
        "print(performance5)\n",
        "\n",
        "# Model 6 \n",
        "prediction_features_6 = model6.predict(features_test)\n",
        "performance6 = model6.evaluate(features_test, labels_test)\n",
        "print(performance6)\n",
        "# Model 7\n",
        "prediction_features_7 = model7.predict(features_test)\n",
        "performance7 = model7.evaluate(features_test, labels_test)\n",
        "print(performance7)\n",
        "# Model 8 \n",
        "prediction_features_8 = model8.predict(features_test)\n",
        "performance8 = model8.evaluate(features_test, labels_test)\n",
        "print(performance8)\n",
        "# Model 9\n",
        "prediction_features_9 = model9.predict(features_test)\n",
        "performance9 = model9.evaluate(features_test, labels_test)\n",
        "print(performance9)\n",
        "# Model 10\n",
        "prediction_features_10 = model10.predict(features_test)\n",
        "performance10 = model10.evaluate(features_test, labels_test)\n",
        "print(performance10)\n",
        "\n",
        "# Model 11 \n",
        "prediction_features_11 = model11.predict(features_test)\n",
        "performance11 = model11.evaluate(features_test, labels_test)\n",
        "print(performance11)\n",
        "# Model 12 \n",
        "prediction_features_12 = model12.predict(features_test)\n",
        "performance12 = model12.evaluate(features_test, labels_test)\n",
        "print(performance12)\n",
        "# Model 13 \n",
        "prediction_features_13 = model13.predict(features_test)\n",
        "performance13 = model13.evaluate(features_test, labels_test)\n",
        "print(performance13)\n",
        "# Model 14 \n",
        "prediction_features_14 = model14.predict(features_test)\n",
        "performance14 = model14.evaluate(features_test, labels_test)\n",
        "print(performance14)\n",
        "# Model 15 \n",
        "prediction_features_15 = model15.predict(features_test)\n",
        "performance15 = model15.evaluate(features_test, labels_test)\n",
        "print(performance15)\n",
        "\n",
        "# Model 16\n",
        "prediction_features_16 = model16.predict(features_test)\n",
        "performance16 = model16.evaluate(features_test, labels_test)\n",
        "print(performance16)\n",
        "# Model 17\n",
        "prediction_features_17 = model17.predict(features_test)\n",
        "performance17 = model17.evaluate(features_test, labels_test)\n",
        "print(performance17)\n",
        "# Model 18 \n",
        "prediction_features_18 = model18.predict(features_test)\n",
        "performance18 = model18.evaluate(features_test, labels_test)\n",
        "print(performance18)\n",
        "# Model 19\n",
        "prediction_features_19 = model19.predict(features_test)\n",
        "performance19 = model19.evaluate(features_test, labels_test)\n",
        "print(performance19)\n",
        "# Model 20 \n",
        "prediction_features_20 = model20.predict(features_test)\n",
        "performance20 = model20.evaluate(features_test, labels_test)\n",
        "print(performance20)\n",
        "\n",
        "# Model 21\n",
        "prediction_features_21 = model21.predict(features_test)\n",
        "performance21 = model21.evaluate(features_test, labels_test)\n",
        "print(performance21)\n",
        "# Model 22\n",
        "prediction_features_22 = model22.predict(features_test)\n",
        "performance22 = model22.evaluate(features_test, labels_test)\n",
        "print(performance22)\n",
        "# Model 23\n",
        "prediction_features_23 = model23.predict(features_test)\n",
        "performance23 = model23.evaluate(features_test, labels_test)\n",
        "print(performance23)\n",
        "# Model 24 \n",
        "prediction_features_24 = model24.predict(features_test)\n",
        "performance24 = model24.evaluate(features_test, labels_test)\n",
        "print(performance24)\n",
        "# Model 25\n",
        "prediction_features_25 = model25.predict(features_test)\n",
        "performance25 = model25.evaluate(features_test, labels_test)\n",
        "print(performance25)\n",
        "\n",
        "# Model 26 \n",
        "prediction_features_26 = model26.predict(features_test)\n",
        "performance26 = model26.evaluate(features_test, labels_test)\n",
        "print(performance26)\n",
        "# Model 27 \n",
        "prediction_features_27 = model27.predict(features_test)\n",
        "performance27 = model27.evaluate(features_test, labels_test)\n",
        "print(performance27)\n",
        "# Model 28 \n",
        "prediction_features_28 = model28.predict(features_test)\n",
        "performance28 = model28.evaluate(features_test, labels_test)\n",
        "print(performance28)\n",
        "# Model 29\n",
        "prediction_features_29 = model29.predict(features_test)\n",
        "performance29 = model29.evaluate(features_test, labels_test)\n",
        "print(performance29)\n",
        "# Model 30 \n",
        "prediction_features_30 = model30.predict(features_test)\n",
        "performance30 = model30.evaluate(features_test, labels_test)\n",
        "print(performance30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kn2xq4Ts7s-"
      },
      "source": [
        "# Averages\n",
        "\n",
        "# Loss\n",
        "loss_avg = (performance1[0] + performance2[0] + performance3[0] + performance4[0] + performance5[0] + performance6[0] + performance7[0] + performance8[0] + performance9[0] + performance10[0]\n",
        "            + performance11[0] + performance12[0] + performance13[0] + performance14[0] + performance15[0] + performance16[0] + performance17[0] + performance18[0] + performance19[0] + performance20[0]\n",
        "            + performance21[0] + performance22[0] + performance23[0] + performance24[0] + performance25[0] + performance26[0] + performance27[0] + performance28[0] + performance29[0] + performance30[0])/30\n",
        "print(\"Loss Average: \", loss_avg)\n",
        "\n",
        "# Accuracy\n",
        "acc_avg =(performance1[1] + performance2[1] + performance3[1] + performance4[1] + performance5[1] + performance6[1] + performance7[1] + performance8[1] + performance9[1] + performance10[1]\n",
        "            + performance11[1] + performance12[1] + performance13[1] + performance14[1] + performance15[1] + performance16[1] + performance17[1] + performance18[1] + performance19[1] + performance20[1]\n",
        "            + performance21[1] + performance22[1] + performance23[1] + performance24[1] + performance25[1] + performance26[1] + performance27[1] + performance28[1] + performance29[1] + performance30[1])/30\n",
        "print(\"Accuraccy Average: \", acc_avg)\n",
        "\n",
        "# Precision\n",
        "precision_avg = (performance1[2] + performance2[2] + performance3[2] + performance4[2] + performance5[2] + performance6[2] + performance7[2] + performance8[2] + performance9[2] + performance10[2]\n",
        "            + performance11[2] + performance12[2] + performance13[2] + performance14[2] + performance15[2] + performance16[2] + performance17[2] + performance18[2] + performance19[2] + performance20[2]\n",
        "            + performance21[2] + performance22[2] + performance23[2] + performance24[2] + performance25[2] + performance26[2] + performance27[2] + performance28[2] + performance29[2] + performance30[2])/30\n",
        "print(\"Precision Average: \", precision_avg)\n",
        "\n",
        "# Recall\n",
        "recall_avg = (performance1[3] + performance2[3] + performance3[3] + performance4[3] + performance5[3] + performance6[3] + performance7[3] + performance8[3] + performance9[3] + performance10[3]\n",
        "            + performance11[3] + performance12[3] + performance13[3] + performance14[3] + performance15[3] + performance16[3] + performance17[3] + performance18[3] + performance19[3] + performance20[3]\n",
        "            + performance21[3] + performance22[3] + performance23[3] + performance24[3] + performance25[3] + performance26[3] + performance27[3] + performance28[3] + performance29[3] + performance30[3])/30\n",
        "print(\"Recall Average: \", recall_avg)\n",
        "\n",
        "# f1_metric\n",
        "f1_avg = (performance1[4] + performance2[4] + performance3[4] + performance4[4] + performance5[4] + performance6[4] + performance7[4] + performance8[4] + performance9[4] + performance10[4]\n",
        "            + performance11[4] + performance12[4] + performance13[4] + performance14[4] + performance15[4] + performance16[4] + performance17[4] + performance18[4] + performance19[4] + performance20[4]\n",
        "            + performance21[4] + performance22[4] + performance23[4] + performance24[4] + performance25[4] + performance26[4] + performance27[4] + performance28[4] + performance29[4] + performance30[4])/30\n",
        "print(\"F1 Average: \", f1_avg)\n",
        "\n",
        "auc_avg = (performance1[5] + performance2[5] + performance3[5] + performance4[5] + performance5[5] + performance6[5] + performance7[5] + performance8[5] + performance9[5] + performance10[5]\n",
        "            + performance11[5] + performance12[5] + performance13[5] + performance14[5] + performance15[5] + performance16[5] + performance17[5] + performance18[5] + performance19[5] + performance20[5]\n",
        "            + performance21[5] + performance22[5] + performance23[5] + performance24[5] + performance25[5] + performance26[5] + performance27[5] + performance28[5] + performance29[5] + performance30[5])/30\n",
        "print(\"AUC Average: \", auc_avg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuwAUg5_KOz4"
      },
      "source": [
        "#Take the standard deviation of the model samples\n",
        "\n",
        "#Loss SE\n",
        "Loss_SE = statistics.stdev([performance1[0], performance2[0], performance3[0], performance4[0], performance5[0],\n",
        "                  performance6[0], performance7[0], performance8[0], performance9[0], performance10[0],\n",
        "                  performance11[0], performance12[0], performance13[0], performance14[0], performance15[0],\n",
        "                  performance16[0], performance17[0], performance18[0], performance19[0], performance20[0], \n",
        "                  performance21[0], performance22[0], performance23[0], performance24[0], performance25[0],\n",
        "                  performance26[0], performance27[0], performance28[0], performance29[0], performance30[0]])\n",
        "print(\"Loss SE:\", Loss_SE)\n",
        "\n",
        "#Accuracy SE\n",
        "Acc_SE = statistics.stdev([performance1[1], performance2[1], performance3[1], performance4[1], performance5[1],\n",
        "                  performance6[1], performance7[1], performance8[1], performance9[1], performance10[1],\n",
        "                  performance11[1], performance12[1], performance13[1], performance14[1], performance15[1],\n",
        "                  performance16[1], performance17[1], performance18[1], performance19[1], performance20[1], \n",
        "                  performance21[1], performance22[1], performance23[1], performance24[1], performance25[1],\n",
        "                  performance26[1], performance27[1], performance28[1], performance29[1], performance30[1]])\n",
        "print(\"Accuraccy SE: \", Acc_SE)\n",
        "\n",
        "#Precision SE\n",
        "precision_SE = statistics.stdev([performance1[2], performance2[2], performance3[2], performance4[2], performance5[2],\n",
        "                  performance6[2], performance7[2], performance8[2], performance9[2], performance10[2],\n",
        "                  performance11[2], performance12[2], performance13[2], performance14[2], performance15[2],\n",
        "                  performance16[2], performance17[2], performance18[2], performance19[2], performance20[2], \n",
        "                  performance21[2], performance22[2], performance23[2], performance24[2], performance25[2],\n",
        "                  performance26[2], performance27[2], performance28[2], performance29[2], performance30[2]])\n",
        "print(\"Precision SE: \", precision_SE)\n",
        "\n",
        "#Recall \n",
        "Recall_SE = statistics.stdev([performance1[3], performance2[3], performance3[3], performance4[3], performance5[3],\n",
        "                  performance6[3], performance7[3], performance8[3], performance9[3], performance10[3],\n",
        "                  performance11[3], performance12[3], performance13[3], performance14[3], performance15[3],\n",
        "                  performance16[3], performance17[3], performance18[3], performance19[3], performance20[3], \n",
        "                  performance21[3], performance22[3], performance23[3], performance24[3], performance25[3],\n",
        "                  performance26[3], performance27[3], performance28[3], performance29[3], performance30[3]])\n",
        "print(\"Recall SE: \", Recall_SE)\n",
        "\n",
        "#F1 Score\n",
        "F1_Score_SE = statistics.stdev([performance1[4], performance2[4], performance3[4], performance4[4], performance5[4],\n",
        "                  performance6[4], performance7[4], performance8[4], performance9[4], performance10[4],\n",
        "                  performance11[4], performance12[4], performance13[4], performance14[4], performance15[4],\n",
        "                  performance16[4], performance17[4], performance18[4], performance19[4], performance20[4], \n",
        "                  performance21[4], performance22[4], performance23[4], performance24[4], performance25[4],\n",
        "                  performance26[4], performance27[4], performance28[4], performance29[4], performance30[4]])\n",
        "print(\"F1_Score_SE: \", F1_Score_SE)\n",
        "\n",
        "#AUC \n",
        "AUC_SE = statistics.stdev([performance1[5], performance2[5], performance3[5], performance4[5], performance5[5] , performance6[5], performance7[5], performance8[5], performance9[5], performance10[5], \n",
        "           performance11[5], performance12[5],performance13[5],performance14[5], performance15[5], performance16[5], performance17[5], performance18[5], performance19[5], performance20[5],\n",
        "           performance21[5], performance22[5], performance23[5], performance24[5], performance25[5], performance26[5], performance27[5], performance28[5], performance29[5], performance30[5]])\n",
        "print(\"AUC SE: \", AUC_SE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMpLKJ4OKt-X"
      },
      "source": [
        "#Tensorflow Graphics\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}