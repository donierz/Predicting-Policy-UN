{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPolicy_Motions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9kxq01msMg9"
      },
      "source": [
        "### BEWARE:Tensorflow is stochastic - this means the model will not be replicated exactly. \n",
        "### Use GA_Load_Model for reproduction\n",
        "\n",
        "#!pip install mlxtend\n",
        "\n",
        "#!pip install h5py pyyaml\n",
        "\n",
        "\n",
        "\n",
        "#!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLftnb5sBe7B"
      },
      "source": [
        "#Load packages\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBsKz40OAGDU"
      },
      "source": [
        "### Packages necessary for model construction \n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.callbacks\n",
        "import datetime \n",
        "import statistics\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os \n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn\n",
        "\n",
        "import pydot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FrEcBaVWVVkb",
        "outputId": "1c33e2e9-6637-49a8-fb76-4eb8d6b0a26c"
      },
      "source": [
        "#Read the Data\n",
        "\n",
        "UN_Data = pd.read_csv('SC_Query_Clean')\n",
        "\n",
        "UN_Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>dates</th>\n",
              "      <th>Class M</th>\n",
              "      <th>Class S</th>\n",
              "      <th>Class I</th>\n",
              "      <th>Class P</th>\n",
              "      <th>Policy Passed</th>\n",
              "      <th>Conflict Indicator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5082</th>\n",
              "      <td>5082</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5083</th>\n",
              "      <td>5083</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5084</th>\n",
              "      <td>5084</td>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5085</th>\n",
              "      <td>5085</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5086</th>\n",
              "      <td>5086</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  dates  Class M  ...  Class P  Policy Passed  Conflict Indicator\n",
              "0              0   2017        1  ...        0              0                   1\n",
              "1              1   2013        1  ...        1              0                   1\n",
              "2              2   2018        1  ...        0              0                   1\n",
              "3              3   2016        1  ...        0              0                   0\n",
              "4              4   1995        1  ...        0              0                   0\n",
              "...          ...    ...      ...  ...      ...            ...                 ...\n",
              "5082        5082   2017        1  ...        0              0                   1\n",
              "5083        5083   2017        1  ...        0              0                   1\n",
              "5084        5084   2002        0  ...        0              0                   0\n",
              "5085        5085   2018        1  ...        0              0                   1\n",
              "5086        5086   2017        1  ...        0              0                   0\n",
              "\n",
              "[5087 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FNUqnWTFS4y2",
        "outputId": "d8dea153-bc29-4f6b-e731-ddaced3b04f7"
      },
      "source": [
        "#Inspect and Clean the Data\n",
        "\n",
        "UN_Data.head(5)\n",
        "\n",
        "UN_Data.drop(['Unnamed: 0'], axis = 1, inplace= True)\n",
        "\n",
        "UN_Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dates</th>\n",
              "      <th>Class M</th>\n",
              "      <th>Class S</th>\n",
              "      <th>Class I</th>\n",
              "      <th>Class P</th>\n",
              "      <th>Policy Passed</th>\n",
              "      <th>Conflict Indicator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1995</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5082</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5083</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5084</th>\n",
              "      <td>2002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5085</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5086</th>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      dates  Class M  Class S  ...  Class P  Policy Passed  Conflict Indicator\n",
              "0      2017        1        0  ...        0              0                   1\n",
              "1      2013        1        0  ...        1              0                   1\n",
              "2      2018        1        0  ...        0              0                   1\n",
              "3      2016        1        0  ...        0              0                   0\n",
              "4      1995        1        0  ...        0              0                   0\n",
              "...     ...      ...      ...  ...      ...            ...                 ...\n",
              "5082   2017        1        0  ...        0              0                   1\n",
              "5083   2017        1        0  ...        0              0                   1\n",
              "5084   2002        0        0  ...        0              0                   0\n",
              "5085   2018        1        0  ...        0              0                   1\n",
              "5086   2017        1        0  ...        0              0                   0\n",
              "\n",
              "[5087 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxcCMRKAAZ8Z",
        "outputId": "0b81e310-5940-4020-8fb2-4128648da643"
      },
      "source": [
        "#Balance Policy Passage\n",
        "\n",
        "# Count samples per class\n",
        "classes_zero = UN_Data[UN_Data['Policy Passed'] == 0]\n",
        "classes_one = UN_Data[UN_Data['Policy Passed'] == 1]\n",
        "\n",
        "# Convert parts into NumPy arrays for weight computation\n",
        "zero_numpy = classes_zero['Policy Passed'].to_numpy()\n",
        "one_numpy = classes_one['Policy Passed'].to_numpy()\n",
        "all_together = np.concatenate((zero_numpy, one_numpy))\n",
        "unique_classes = np.unique(all_together)\n",
        "\n",
        "# Compute weights\n",
        "weights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)\n",
        "weights = dict(enumerate(weights))\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.7088907469342252, 1: 1.6967978652434956}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "tkn1c4RqeEdO",
        "outputId": "f4d20e47-d001-4a92-bf67-b8a8270f2c22"
      },
      "source": [
        "#Inspect the data by key descriptive statistics\n",
        "\n",
        "UN_Data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dates</th>\n",
              "      <th>Class M</th>\n",
              "      <th>Class S</th>\n",
              "      <th>Class I</th>\n",
              "      <th>Class P</th>\n",
              "      <th>Policy Passed</th>\n",
              "      <th>Conflict Indicator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2007.883428</td>\n",
              "      <td>0.930214</td>\n",
              "      <td>0.064478</td>\n",
              "      <td>0.038530</td>\n",
              "      <td>0.064085</td>\n",
              "      <td>0.294673</td>\n",
              "      <td>0.487124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.211264</td>\n",
              "      <td>0.288127</td>\n",
              "      <td>0.530036</td>\n",
              "      <td>0.228025</td>\n",
              "      <td>0.251268</td>\n",
              "      <td>0.455940</td>\n",
              "      <td>0.499883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2002.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2008.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             dates      Class M  ...  Policy Passed  Conflict Indicator\n",
              "count  5087.000000  5087.000000  ...    5087.000000         5087.000000\n",
              "mean   2007.883428     0.930214  ...       0.294673            0.487124\n",
              "std       7.211264     0.288127  ...       0.455940            0.499883\n",
              "min    1994.000000     0.000000  ...       0.000000            0.000000\n",
              "25%    2002.000000     1.000000  ...       0.000000            0.000000\n",
              "50%    2008.000000     1.000000  ...       0.000000            0.000000\n",
              "75%    2014.000000     1.000000  ...       1.000000            1.000000\n",
              "max    2019.000000     5.000000  ...       1.000000            1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "1c56fLBjJKA3",
        "outputId": "15fd9de3-66ce-4d48-ba99-755512b6fc4d"
      },
      "source": [
        "#Group the data by our label (dependent variable) of policy passage\n",
        "\n",
        "UN_Data.groupby(['Policy Passed']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dates</th>\n",
              "      <th>Class M</th>\n",
              "      <th>Class S</th>\n",
              "      <th>Class I</th>\n",
              "      <th>Class P</th>\n",
              "      <th>Conflict Indicator</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Policy Passed</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3588</td>\n",
              "      <td>3588</td>\n",
              "      <td>3588</td>\n",
              "      <td>3588</td>\n",
              "      <td>3588</td>\n",
              "      <td>3588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1499</td>\n",
              "      <td>1499</td>\n",
              "      <td>1499</td>\n",
              "      <td>1499</td>\n",
              "      <td>1499</td>\n",
              "      <td>1499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               dates  Class M  Class S  Class I  Class P  Conflict Indicator\n",
              "Policy Passed                                                               \n",
              "0               3588     3588     3588     3588     3588                3588\n",
              "1               1499     1499     1499     1499     1499                1499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "lUEe-fLzAZ8a",
        "outputId": "8cd8e7a3-7aee-49d7-a5dd-45f2eb3efee4"
      },
      "source": [
        "#Normalize the data \n",
        "\n",
        "UN_Data1 = tf.keras.utils.normalize(UN_Data.drop(columns = ['Policy Passed']))\n",
        "\n",
        "UN_Data1['Policy Passed'] = UN_Data['Policy Passed']\n",
        "\n",
        "UN_Data1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dates</th>\n",
              "      <th>Class M</th>\n",
              "      <th>Class S</th>\n",
              "      <th>Class I</th>\n",
              "      <th>Class P</th>\n",
              "      <th>Conflict Indicator</th>\n",
              "      <th>Policy Passed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.087000e+03</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "      <td>5087.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.294673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.004761e-07</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000263</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.455940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.999455e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.002480</td>\n",
              "      <td>0.010416</td>\n",
              "      <td>0.002972</td>\n",
              "      <td>0.001494</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              dates      Class M  ...  Conflict Indicator  Policy Passed\n",
              "count  5.087000e+03  5087.000000  ...         5087.000000    5087.000000\n",
              "mean   9.999998e-01     0.000463  ...            0.000242       0.294673\n",
              "std    9.004761e-07     0.000143  ...            0.000249       0.455940\n",
              "min    9.999455e-01     0.000000  ...            0.000000       0.000000\n",
              "25%    9.999998e-01     0.000496  ...            0.000000       0.000000\n",
              "50%    9.999999e-01     0.000498  ...            0.000000       0.000000\n",
              "75%    9.999999e-01     0.000499  ...            0.000497       1.000000\n",
              "max    1.000000e+00     0.002480  ...            0.000502       1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6BF8hmXGEnF"
      },
      "source": [
        "#Divide our variables between the independent variables (features) and dependent variables (policy passage)\n",
        "\n",
        "labels = UN_Data1 ['Policy Passed']\n",
        "features = UN_Data1.drop(columns= ['Policy Passed', 'Conflict Indicator'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWD_YiigAZ8a"
      },
      "source": [
        "#Drop Null Values\n",
        "\n",
        "features = features.fillna(0)\n",
        "labels = labels.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FJRWpUNH8Dk",
        "outputId": "701f2b6a-e01a-4afb-f455-bd59572b2bb4"
      },
      "source": [
        "#Inspect shape of features\n",
        "\n",
        "features = pd.get_dummies(features)\n",
        "features.shape[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5087, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oGgPi4CG0xx"
      },
      "source": [
        "#Define type of feature and label values\n",
        "\n",
        "features = features.values.astype('float32')\n",
        "labels = labels.values.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOea_aP_HPSE"
      },
      "source": [
        "#Data Sets for Training\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)\n",
        "features_train, features_validation, labels_train, labels_validation = train_test_split(features_train, labels_train, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSYOIsh5vq4"
      },
      "source": [
        "#Define Precision, Recall, and F1 score metrics\n",
        "import keras.backend as K\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall_keras\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    weights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VQ_OqkCHkLM"
      },
      "source": [
        "#Create your model\n",
        "\n",
        "model1 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'), keras.layers.Dense(1, activation='sigmoid')])\n",
        "model2 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model3 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model4 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model5 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model6 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model7 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model8 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model9 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model10 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model11 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model12 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model13 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model14 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model15 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model16 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model17 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model18 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model19 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model20 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model21 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model22 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model23 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model24 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model25 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model26 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model27 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model28 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model29 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])\n",
        "model30 = tf.keras.Sequential([keras.layers.Dense(124, input_shape=(5,)),keras.layers.Dropout(.15),keras.layers.Dense(64, activation= 'relu'),keras.layers.Dropout(.2),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "7JTlq8aH8mzi",
        "outputId": "dec09b28-2531-48fa-fdd6-5c09f4e21f6b"
      },
      "source": [
        "### Inspect form of model\n",
        "\n",
        "tf.keras.utils.plot_model(model1, to_file='model.png', show_shapes = True, show_dtype=True, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Vb8b-qSIQ4",
        "outputId": "36e9a3fc-19ff-4890-84c6-1763533c7652"
      },
      "source": [
        "#Check Trainable Parameters\n",
        "# Note: All the models are similarly structured\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 124)               744       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8000      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,801\n",
            "Trainable params: 9,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyx2tehuTPfe"
      },
      "source": [
        "#Set checkpoints, metrics, loss, and optimizer functions for the model\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model7.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model8.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model9.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model10.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model11.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model12.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model13.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model14.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model15.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model16.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model17.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model18.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model19.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model20.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model21.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model22.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model23.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model24.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model25.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "\n",
        "model26.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model27.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model28.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model29.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])\n",
        "model30.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc', precision, recall, f1_metric, tf.keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhwA7DthFS72",
        "outputId": "e112ba51-e976-4a27-e1d0-7e3534bb40ab"
      },
      "source": [
        "#Run the model\n",
        "\n",
        "print(\"Model 1 Fitting\")\n",
        "history1 = model1.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 2 Fitting\")\n",
        "history2 = model2.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 3 Fitting\")\n",
        "history3 = model3.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 4 Fitting\")\n",
        "history4 = model4.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 5 Fitting\")\n",
        "history5 = model5.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 6 Fitting\")\n",
        "history6 = model6.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 7 Fitting\")\n",
        "history7 = model7.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 8 Fitting\")\n",
        "history8 = model8.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 9 Fitting\")\n",
        "history9 = model9.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 10 Fitting\")\n",
        "history10 = model10.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 11 Fitting\")\n",
        "history11 = model11.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 12 Fitting\")\n",
        "history12 = model12.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 13 Fitting\")\n",
        "history13 = model13.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 14 Fitting\")\n",
        "history14 = model14.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 15 Fitting\")\n",
        "history15 = model15.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 16 Fitting\")\n",
        "history16 = model16.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 17 Fitting\")\n",
        "history17 = model17.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 18 Fitting\")\n",
        "history18 = model18.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 19 Fitting\")\n",
        "history19 = model19.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 20 Fitting\")\n",
        "history20 = model20.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 21 Fitting\")\n",
        "history21 = model21.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 22 Fitting\")\n",
        "history22 = model22.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 23 Fitting\")\n",
        "history23 = model23.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 24 Fitting\")\n",
        "history24 = model24.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 25 Fitting\")\n",
        "history25 = model25.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "\n",
        "print(\"Model 26 Fitting\")\n",
        "history26 = model26.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 27 Fitting\")\n",
        "history27 = model27.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 28 Fitting\")\n",
        "history28 = model28.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 29 Fitting\")\n",
        "history29 = model29.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])\n",
        "print(\"Model 30 Fitting\")\n",
        "history30 = model30.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), class_weight = weights, callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 4s 10ms/step - loss: 0.7028 - acc: 0.4296 - precision: 0.3128 - recall: 0.7164 - f1_metric: 0.4017 - auc: 0.5078 - val_loss: 0.7211 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.4093 - precision: 0.2925 - recall: 0.7289 - f1_metric: 0.3937 - auc: 0.4921 - val_loss: 0.7104 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.4335 - precision: 0.3054 - recall: 0.6707 - f1_metric: 0.3800 - auc: 0.5071 - val_loss: 0.7283 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6991 - acc: 0.4428 - precision: 0.3026 - recall: 0.6256 - f1_metric: 0.3873 - auc: 0.4945 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6903 - acc: 0.4717 - precision: 0.2782 - recall: 0.5662 - f1_metric: 0.3164 - auc: 0.4945 - val_loss: 0.7067 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7021 - acc: 0.3877 - precision: 0.3185 - recall: 0.8144 - f1_metric: 0.4287 - auc: 0.4753 - val_loss: 0.6954 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.3836 - precision: 0.2981 - recall: 0.7764 - f1_metric: 0.4209 - auc: 0.5061 - val_loss: 0.6915 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.3978 - precision: 0.3099 - recall: 0.7683 - f1_metric: 0.4234 - auc: 0.4992 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.3446 - precision: 0.2873 - recall: 0.8453 - f1_metric: 0.4160 - auc: 0.4907 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6990 - acc: 0.3585 - precision: 0.3078 - recall: 0.8918 - f1_metric: 0.4504 - auc: 0.5141 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7002 - acc: 0.4239 - precision: 0.3050 - recall: 0.6737 - f1_metric: 0.3985 - auc: 0.4888 - val_loss: 0.6921 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6991 - acc: 0.3830 - precision: 0.3114 - recall: 0.8310 - f1_metric: 0.4394 - auc: 0.5057 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.3650 - precision: 0.3002 - recall: 0.8157 - f1_metric: 0.4319 - auc: 0.4702 - val_loss: 0.6943 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.5365 - precision: 0.2591 - recall: 0.3114 - f1_metric: 0.2505 - auc: 0.4757 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7030 - acc: 0.3315 - precision: 0.3123 - recall: 0.9575 - f1_metric: 0.4635 - auc: 0.5111 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.4702 - precision: 0.3174 - recall: 0.5527 - f1_metric: 0.3578 - auc: 0.4897 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.4106 - precision: 0.3113 - recall: 0.7237 - f1_metric: 0.3980 - auc: 0.4963 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5441 - precision: 0.2812 - recall: 0.3316 - f1_metric: 0.2339 - auc: 0.4761 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6950 - acc: 0.3758 - precision: 0.3034 - recall: 0.8419 - f1_metric: 0.4351 - auc: 0.4738 - val_loss: 0.7046 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7001 - acc: 0.3382 - precision: 0.3037 - recall: 0.8973 - f1_metric: 0.4418 - auc: 0.5065 - val_loss: 0.6954 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6944 - acc: 0.3387 - precision: 0.2938 - recall: 0.8765 - f1_metric: 0.4312 - auc: 0.5139 - val_loss: 0.6909 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc: 0.4977\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.4951 - precision: 0.2988 - recall: 0.4663 - f1_metric: 0.3308 - auc: 0.4686 - val_loss: 0.6908 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.3655 - precision: 0.3094 - recall: 0.8078 - f1_metric: 0.4270 - auc: 0.4759 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7002 - acc: 0.3672 - precision: 0.3076 - recall: 0.8834 - f1_metric: 0.4466 - auc: 0.4941 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.4701 - precision: 0.2996 - recall: 0.6131 - f1_metric: 0.3839 - auc: 0.5074 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6872 - acc: 0.3932 - precision: 0.2905 - recall: 0.7719 - f1_metric: 0.4101 - auc: 0.5016 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.3575 - precision: 0.2908 - recall: 0.8308 - f1_metric: 0.4238 - auc: 0.4863 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.2964 - precision: 0.2930 - recall: 0.9722 - f1_metric: 0.4420 - auc: 0.4972 - val_loss: 0.7010 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.3127 - precision: 0.2981 - recall: 0.9714 - f1_metric: 0.4509 - auc: 0.5133 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.4242 - precision: 0.3195 - recall: 0.6836 - f1_metric: 0.3977 - auc: 0.5070 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc: 0.5000\n",
            "Model 2 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6957 - acc: 0.5516 - precision: 0.2290 - recall: 0.3793 - f1_metric: 0.2350 - auc_1: 0.4850 - val_loss: 0.7042 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6974 - acc: 0.4754 - precision: 0.2816 - recall: 0.4835 - f1_metric: 0.3296 - auc_1: 0.4760 - val_loss: 0.7198 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6940 - acc: 0.4176 - precision: 0.2883 - recall: 0.6603 - f1_metric: 0.3687 - auc_1: 0.4758 - val_loss: 0.6843 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_1: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.6235 - precision: 0.2648 - recall: 0.2752 - f1_metric: 0.1920 - auc_1: 0.5312 - val_loss: 0.6813 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_1: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7011 - acc: 0.4727 - precision: 0.3093 - recall: 0.5477 - f1_metric: 0.3465 - auc_1: 0.4929 - val_loss: 0.7010 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7035 - acc: 0.4018 - precision: 0.3054 - recall: 0.7417 - f1_metric: 0.4123 - auc_1: 0.5022 - val_loss: 0.7054 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.3779 - precision: 0.3051 - recall: 0.8448 - f1_metric: 0.4306 - auc_1: 0.5002 - val_loss: 0.7090 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.4059 - precision: 0.3073 - recall: 0.7618 - f1_metric: 0.4217 - auc_1: 0.4969 - val_loss: 0.6922 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_1: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.5064 - precision: 0.2986 - recall: 0.4850 - f1_metric: 0.3448 - auc_1: 0.4981 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.4299 - precision: 0.2847 - recall: 0.6164 - f1_metric: 0.3696 - auc_1: 0.4800 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.4433 - precision: 0.3082 - recall: 0.6343 - f1_metric: 0.3726 - auc_1: 0.4765 - val_loss: 0.7045 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.5507 - precision: 0.2553 - recall: 0.3806 - f1_metric: 0.2322 - auc_1: 0.4917 - val_loss: 0.7024 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6969 - acc: 0.3055 - precision: 0.2996 - recall: 0.9834 - f1_metric: 0.4537 - auc_1: 0.4780 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7007 - acc: 0.3660 - precision: 0.3032 - recall: 0.8373 - f1_metric: 0.4351 - auc_1: 0.5056 - val_loss: 0.7038 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6973 - acc: 0.4414 - precision: 0.3082 - recall: 0.6917 - f1_metric: 0.4072 - auc_1: 0.5169 - val_loss: 0.7003 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6880 - acc: 0.4609 - precision: 0.2897 - recall: 0.5800 - f1_metric: 0.3498 - auc_1: 0.4886 - val_loss: 0.7122 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6991 - acc: 0.3163 - precision: 0.3044 - recall: 0.9798 - f1_metric: 0.4566 - auc_1: 0.4848 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.3210 - precision: 0.3032 - recall: 0.9672 - f1_metric: 0.4560 - auc_1: 0.5059 - val_loss: 0.7009 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.3980 - precision: 0.2937 - recall: 0.7515 - f1_metric: 0.4079 - auc_1: 0.4944 - val_loss: 0.6918 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_1: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.4702 - precision: 0.2949 - recall: 0.5468 - f1_metric: 0.3680 - auc_1: 0.4905 - val_loss: 0.6938 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.3456 - precision: 0.3039 - recall: 0.9003 - f1_metric: 0.4440 - auc_1: 0.4796 - val_loss: 0.6933 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.4055 - precision: 0.3009 - recall: 0.7637 - f1_metric: 0.4211 - auc_1: 0.5003 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.3322 - precision: 0.2928 - recall: 0.9083 - f1_metric: 0.4320 - auc_1: 0.4857 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.3111 - precision: 0.2906 - recall: 0.9410 - f1_metric: 0.4346 - auc_1: 0.4943 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6997 - acc: 0.3044 - precision: 0.3044 - recall: 1.0000 - f1_metric: 0.4635 - auc_1: 0.4965 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6890 - acc: 0.2921 - precision: 0.2862 - recall: 0.9766 - f1_metric: 0.4354 - auc_1: 0.4908 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7014 - acc: 0.3072 - precision: 0.3072 - recall: 1.0000 - f1_metric: 0.4663 - auc_1: 0.5017 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6848 - acc: 0.2854 - precision: 0.2828 - recall: 0.9962 - f1_metric: 0.4340 - auc_1: 0.5005 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6951 - acc: 0.3269 - precision: 0.2984 - recall: 0.9317 - f1_metric: 0.4467 - auc_1: 0.5007 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7049 - acc: 0.3450 - precision: 0.3164 - recall: 0.9410 - f1_metric: 0.4678 - auc_1: 0.5006 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_1: 0.5000\n",
            "Model 3 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6890 - acc: 0.6415 - precision: 0.3559 - recall: 0.2134 - f1_metric: 0.2102 - auc_2: 0.5190 - val_loss: 0.7077 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6993 - acc: 0.3463 - precision: 0.3009 - recall: 0.8831 - f1_metric: 0.4402 - auc_2: 0.4865 - val_loss: 0.6918 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_2: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6997 - acc: 0.4410 - precision: 0.3058 - recall: 0.6500 - f1_metric: 0.3906 - auc_2: 0.4855 - val_loss: 0.6877 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_2: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.6185 - precision: 0.2528 - recall: 0.1823 - f1_metric: 0.1770 - auc_2: 0.4906 - val_loss: 0.7009 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7071 - acc: 0.4272 - precision: 0.2933 - recall: 0.7685 - f1_metric: 0.3976 - auc_2: 0.5109 - val_loss: 0.7093 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.3943 - precision: 0.2808 - recall: 0.6875 - f1_metric: 0.3663 - auc_2: 0.4707 - val_loss: 0.6880 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_2: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6974 - acc: 0.5432 - precision: 0.3342 - recall: 0.4445 - f1_metric: 0.3241 - auc_2: 0.5144 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6947 - acc: 0.5342 - precision: 0.3059 - recall: 0.4486 - f1_metric: 0.3298 - auc_2: 0.5170 - val_loss: 0.6866 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_2: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7018 - acc: 0.5546 - precision: 0.2477 - recall: 0.2961 - f1_metric: 0.2351 - auc_2: 0.4681 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.3863 - precision: 0.2848 - recall: 0.7086 - f1_metric: 0.3843 - auc_2: 0.4883 - val_loss: 0.7021 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3325 - precision: 0.2992 - recall: 0.9146 - f1_metric: 0.4447 - auc_2: 0.4928 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.3689 - precision: 0.2745 - recall: 0.6688 - f1_metric: 0.3755 - auc_2: 0.4477 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.4903 - precision: 0.2636 - recall: 0.4957 - f1_metric: 0.3059 - auc_2: 0.5013 - val_loss: 0.7018 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6913 - acc: 0.3446 - precision: 0.2915 - recall: 0.8686 - f1_metric: 0.4278 - auc_2: 0.5117 - val_loss: 0.6990 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7029 - acc: 0.3479 - precision: 0.3016 - recall: 0.8522 - f1_metric: 0.4386 - auc_2: 0.4931 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.4772 - precision: 0.3170 - recall: 0.5877 - f1_metric: 0.3841 - auc_2: 0.5193 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.4757 - precision: 0.3046 - recall: 0.5382 - f1_metric: 0.3365 - auc_2: 0.4997 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.4949\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6913 - acc: 0.4292 - precision: 0.2754 - recall: 0.5972 - f1_metric: 0.3445 - auc_2: 0.4680 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.3725 - precision: 0.2974 - recall: 0.8295 - f1_metric: 0.4245 - auc_2: 0.4944 - val_loss: 0.6935 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7019 - acc: 0.3564 - precision: 0.3118 - recall: 0.8897 - f1_metric: 0.4531 - auc_2: 0.5056 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5237 - precision: 0.3099 - recall: 0.4625 - f1_metric: 0.3323 - auc_2: 0.5071 - val_loss: 0.7031 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.3088 - precision: 0.2923 - recall: 0.9430 - f1_metric: 0.4411 - auc_2: 0.4913 - val_loss: 0.7000 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.3419 - precision: 0.2988 - recall: 0.8792 - f1_metric: 0.4334 - auc_2: 0.4925 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.3215 - precision: 0.2967 - recall: 0.9199 - f1_metric: 0.4425 - auc_2: 0.5048 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6949 - acc: 0.3170 - precision: 0.2952 - recall: 0.9441 - f1_metric: 0.4430 - auc_2: 0.4751 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7062 - acc: 0.3271 - precision: 0.3134 - recall: 0.9580 - f1_metric: 0.4671 - auc_2: 0.4895 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.3272 - precision: 0.2913 - recall: 0.8932 - f1_metric: 0.4333 - auc_2: 0.4955 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.4065 - precision: 0.3144 - recall: 0.7628 - f1_metric: 0.4134 - auc_2: 0.5049 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.4161 - precision: 0.2787 - recall: 0.6824 - f1_metric: 0.3607 - auc_2: 0.4870 - val_loss: 0.6998 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6917 - acc: 0.2990 - precision: 0.2926 - recall: 0.9875 - f1_metric: 0.4417 - auc_2: 0.4853 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_2: 0.5000\n",
            "Model 4 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6882 - acc: 0.6560 - precision: 0.1482 - recall: 0.1749 - f1_metric: 0.1146 - auc_3: 0.4904 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7092 - acc: 0.4209 - precision: 0.3131 - recall: 0.7364 - f1_metric: 0.4167 - auc_3: 0.5029 - val_loss: 0.6896 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_3: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.6077 - precision: 0.2614 - recall: 0.2201 - f1_metric: 0.1735 - auc_3: 0.5034 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.3990 - precision: 0.2831 - recall: 0.6848 - f1_metric: 0.3767 - auc_3: 0.4709 - val_loss: 0.6994 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.7031 - acc: 0.3161 - precision: 0.3064 - recall: 0.9606 - f1_metric: 0.4578 - auc_3: 0.4650 - val_loss: 0.6997 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.3338 - precision: 0.3042 - recall: 0.9338 - f1_metric: 0.4522 - auc_3: 0.5035 - val_loss: 0.6996 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7029 - acc: 0.3291 - precision: 0.3104 - recall: 0.9546 - f1_metric: 0.4635 - auc_3: 0.4900 - val_loss: 0.6980 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.3139 - precision: 0.3055 - recall: 0.9788 - f1_metric: 0.4586 - auc_3: 0.5022 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6968 - acc: 0.3579 - precision: 0.2956 - recall: 0.8238 - f1_metric: 0.4275 - auc_3: 0.4909 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.4575 - precision: 0.3022 - recall: 0.6285 - f1_metric: 0.3880 - auc_3: 0.5050 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.3115 - precision: 0.3082 - recall: 0.9787 - f1_metric: 0.4618 - auc_3: 0.4838 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.3024 - precision: 0.2983 - recall: 0.9905 - f1_metric: 0.4529 - auc_3: 0.5044 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6946 - acc: 0.3046 - precision: 0.2977 - recall: 0.9896 - f1_metric: 0.4519 - auc_3: 0.5164 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.3061 - precision: 0.3012 - recall: 0.9794 - f1_metric: 0.4548 - auc_3: 0.5017 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6964 - acc: 0.3139 - precision: 0.2980 - recall: 0.9542 - f1_metric: 0.4453 - auc_3: 0.5087 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6980 - acc: 0.3264 - precision: 0.3029 - recall: 0.9321 - f1_metric: 0.4480 - auc_3: 0.4967 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6887 - acc: 0.2920 - precision: 0.2866 - recall: 0.9820 - f1_metric: 0.4380 - auc_3: 0.5027 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.2978 - precision: 0.2953 - recall: 0.9924 - f1_metric: 0.4511 - auc_3: 0.5006 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3185 - precision: 0.2963 - recall: 0.9518 - f1_metric: 0.4462 - auc_3: 0.4962 - val_loss: 0.6980 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3009 - precision: 0.2981 - recall: 0.9888 - f1_metric: 0.4534 - auc_3: 0.4977 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.2986 - precision: 0.2931 - recall: 0.9862 - f1_metric: 0.4462 - auc_3: 0.4882 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6891 - acc: 0.2932 - precision: 0.2889 - recall: 0.9907 - f1_metric: 0.4423 - auc_3: 0.5016 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.3092 - precision: 0.3081 - recall: 0.9991 - f1_metric: 0.4656 - auc_3: 0.5019 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3046 - precision: 0.2951 - recall: 0.9824 - f1_metric: 0.4475 - auc_3: 0.4999 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6878 - acc: 0.3197 - precision: 0.2873 - recall: 0.9201 - f1_metric: 0.4324 - auc_3: 0.4989 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.2951 - precision: 0.2930 - recall: 0.9836 - f1_metric: 0.4467 - auc_3: 0.4879 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7007 - acc: 0.3049 - precision: 0.3047 - recall: 0.9915 - f1_metric: 0.4610 - auc_3: 0.4962 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7046 - acc: 0.3113 - precision: 0.3115 - recall: 0.9984 - f1_metric: 0.4677 - auc_3: 0.5050 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.3041 - precision: 0.3038 - recall: 0.9997 - f1_metric: 0.4592 - auc_3: 0.4960 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6894 - acc: 0.2914 - precision: 0.2885 - recall: 0.9906 - f1_metric: 0.4413 - auc_3: 0.5008 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_3: 0.5000\n",
            "Model 5 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 9ms/step - loss: 0.6969 - acc: 0.3431 - precision: 0.2963 - recall: 0.8863 - f1_metric: 0.4230 - auc_4: 0.4755 - val_loss: 0.6901 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_4: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.3958 - precision: 0.3103 - recall: 0.7945 - f1_metric: 0.4343 - auc_4: 0.4955 - val_loss: 0.6852 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_4: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6880 - acc: 0.6641 - precision: 0.2855 - recall: 0.1225 - f1_metric: 0.1333 - auc_4: 0.5124 - val_loss: 0.6994 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7029 - acc: 0.3962 - precision: 0.3134 - recall: 0.7953 - f1_metric: 0.4235 - auc_4: 0.4955 - val_loss: 0.6912 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_4: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.5284 - precision: 0.3179 - recall: 0.3897 - f1_metric: 0.2984 - auc_4: 0.4882 - val_loss: 0.7009 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.4789 - precision: 0.2507 - recall: 0.4602 - f1_metric: 0.2902 - auc_4: 0.4783 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3661 - precision: 0.3007 - recall: 0.8382 - f1_metric: 0.4319 - auc_4: 0.4932 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.4288 - precision: 0.3046 - recall: 0.7294 - f1_metric: 0.4161 - auc_4: 0.4881 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6953 - acc: 0.3096 - precision: 0.2978 - recall: 0.9727 - f1_metric: 0.4504 - auc_4: 0.5045 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3150 - precision: 0.3047 - recall: 0.9811 - f1_metric: 0.4591 - auc_4: 0.5113 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 0.3320 - precision: 0.3002 - recall: 0.8893 - f1_metric: 0.4384 - auc_4: 0.4815 - val_loss: 0.6915 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_4: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.6345 - precision: 0.2523 - recall: 0.1487 - f1_metric: 0.1489 - auc_4: 0.4784 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.6124 - precision: 0.2660 - recall: 0.2183 - f1_metric: 0.1820 - auc_4: 0.5052 - val_loss: 0.7038 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6889 - acc: 0.4641 - precision: 0.2947 - recall: 0.5755 - f1_metric: 0.3289 - auc_4: 0.5045 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.3462 - precision: 0.2954 - recall: 0.8578 - f1_metric: 0.4300 - auc_4: 0.4783 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_4: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.4620 - precision: 0.3040 - recall: 0.5941 - f1_metric: 0.3786 - auc_4: 0.4916 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7011 - acc: 0.3446 - precision: 0.3072 - recall: 0.9039 - f1_metric: 0.4521 - auc_4: 0.4835 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.3998 - precision: 0.3070 - recall: 0.7724 - f1_metric: 0.4304 - auc_4: 0.5033 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.3988 - precision: 0.2839 - recall: 0.6731 - f1_metric: 0.3801 - auc_4: 0.4776 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7041 - acc: 0.3283 - precision: 0.3139 - recall: 0.9723 - f1_metric: 0.4690 - auc_4: 0.4853 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6916 - acc: 0.3184 - precision: 0.2932 - recall: 0.9356 - f1_metric: 0.4401 - auc_4: 0.5053 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.3074 - precision: 0.3019 - recall: 0.9941 - f1_metric: 0.4569 - auc_4: 0.5039 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.3020 - precision: 0.2985 - recall: 0.9733 - f1_metric: 0.4511 - auc_4: 0.4811 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.3146 - precision: 0.3089 - recall: 0.9976 - f1_metric: 0.4675 - auc_4: 0.4967 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6944 - acc: 0.3150 - precision: 0.2961 - recall: 0.9559 - f1_metric: 0.4444 - auc_4: 0.5001 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5003\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6833 - acc: 0.3578 - precision: 0.2883 - recall: 0.8797 - f1_metric: 0.4252 - auc_4: 0.4937 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.2964 - precision: 0.2962 - recall: 1.0000 - f1_metric: 0.4502 - auc_4: 0.4873 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7028 - acc: 0.3091 - precision: 0.3089 - recall: 0.9993 - f1_metric: 0.4658 - auc_4: 0.4882 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.3037 - precision: 0.2970 - recall: 0.9810 - f1_metric: 0.4486 - auc_4: 0.4910 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.3031 - precision: 0.3007 - recall: 0.9921 - f1_metric: 0.4534 - auc_4: 0.4881 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_4: 0.4977\n",
            "Model 6 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6883 - acc: 0.5837 - precision: 0.2070 - recall: 0.2372 - f1_metric: 0.1700 - auc_5: 0.4842 - val_loss: 0.7135 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.4261 - precision: 0.3050 - recall: 0.7081 - f1_metric: 0.3973 - auc_5: 0.4969 - val_loss: 0.6864 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5008\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.4594 - precision: 0.2954 - recall: 0.6048 - f1_metric: 0.3870 - auc_5: 0.4820 - val_loss: 0.7062 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3802 - precision: 0.3013 - recall: 0.8070 - f1_metric: 0.4192 - auc_5: 0.5067 - val_loss: 0.7089 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7014 - acc: 0.3503 - precision: 0.3017 - recall: 0.8629 - f1_metric: 0.4358 - auc_5: 0.4875 - val_loss: 0.6791 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.5642 - precision: 0.3515 - recall: 0.3193 - f1_metric: 0.2630 - auc_5: 0.4798 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7013 - acc: 0.3690 - precision: 0.2972 - recall: 0.7960 - f1_metric: 0.4204 - auc_5: 0.4748 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.3843 - precision: 0.2921 - recall: 0.7799 - f1_metric: 0.4102 - auc_5: 0.5017 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5946\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6855 - acc: 0.3555 - precision: 0.2810 - recall: 0.8126 - f1_metric: 0.4060 - auc_5: 0.4899 - val_loss: 0.7090 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6865 - acc: 0.4257 - precision: 0.2843 - recall: 0.6451 - f1_metric: 0.3529 - auc_5: 0.4782 - val_loss: 0.6999 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6886 - acc: 0.3301 - precision: 0.2939 - recall: 0.9475 - f1_metric: 0.4403 - auc_5: 0.5233 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 0.3822 - precision: 0.3022 - recall: 0.7990 - f1_metric: 0.4275 - auc_5: 0.4919 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6863 - acc: 0.4618 - precision: 0.3039 - recall: 0.6068 - f1_metric: 0.3662 - auc_5: 0.5122 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6947 - acc: 0.3635 - precision: 0.2949 - recall: 0.8260 - f1_metric: 0.4247 - auc_5: 0.4840 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.3937 - precision: 0.2923 - recall: 0.7425 - f1_metric: 0.4047 - auc_5: 0.4902 - val_loss: 0.6922 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6999 - acc: 0.4615 - precision: 0.2890 - recall: 0.5293 - f1_metric: 0.3573 - auc_5: 0.4997 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.3324 - precision: 0.3055 - recall: 0.9476 - f1_metric: 0.4554 - auc_5: 0.4916 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.3516 - precision: 0.3171 - recall: 0.9302 - f1_metric: 0.4652 - auc_5: 0.4949 - val_loss: 0.6946 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.3228 - precision: 0.3050 - recall: 0.9417 - f1_metric: 0.4549 - auc_5: 0.4943 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3260 - precision: 0.3039 - recall: 0.9411 - f1_metric: 0.4532 - auc_5: 0.4987 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.3798 - precision: 0.3141 - recall: 0.8625 - f1_metric: 0.4516 - auc_5: 0.5080 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.3729 - precision: 0.3005 - recall: 0.8220 - f1_metric: 0.4256 - auc_5: 0.4772 - val_loss: 0.6853 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7025 - acc: 0.4540 - precision: 0.3168 - recall: 0.6116 - f1_metric: 0.3735 - auc_5: 0.5018 - val_loss: 0.6903 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.5248 - precision: 0.3208 - recall: 0.5092 - f1_metric: 0.3751 - auc_5: 0.5499 - val_loss: 0.6925 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7012 - acc: 0.4398 - precision: 0.2950 - recall: 0.6014 - f1_metric: 0.3827 - auc_5: 0.4827 - val_loss: 0.6879 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7070 - acc: 0.4013 - precision: 0.3298 - recall: 0.7753 - f1_metric: 0.4300 - auc_5: 0.4851 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.4149 - precision: 0.2704 - recall: 0.5985 - f1_metric: 0.3605 - auc_5: 0.4793 - val_loss: 0.6923 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_5: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.3221 - precision: 0.2842 - recall: 0.8823 - f1_metric: 0.4222 - auc_5: 0.4806 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.2984 - precision: 0.2982 - recall: 1.0000 - f1_metric: 0.4538 - auc_5: 0.4768 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.2995 - precision: 0.2997 - recall: 0.9992 - f1_metric: 0.4568 - auc_5: 0.4970 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_5: 0.5000\n",
            "Model 7 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6896 - acc: 0.5626 - precision: 0.2277 - recall: 0.4583 - f1_metric: 0.2592 - auc_6: 0.4933 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.4546 - precision: 0.3064 - recall: 0.6284 - f1_metric: 0.3938 - auc_6: 0.5245 - val_loss: 0.6913 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_6: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.4466 - precision: 0.3155 - recall: 0.6535 - f1_metric: 0.3969 - auc_6: 0.5149 - val_loss: 0.6918 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_6: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6891 - acc: 0.5429 - precision: 0.2825 - recall: 0.3984 - f1_metric: 0.3036 - auc_6: 0.4823 - val_loss: 0.7049 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7057 - acc: 0.4365 - precision: 0.3263 - recall: 0.7350 - f1_metric: 0.4296 - auc_6: 0.5130 - val_loss: 0.7107 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7021 - acc: 0.3500 - precision: 0.3055 - recall: 0.8791 - f1_metric: 0.4445 - auc_6: 0.4858 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6879 - acc: 0.4234 - precision: 0.2938 - recall: 0.6755 - f1_metric: 0.3867 - auc_6: 0.5087 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7051 - acc: 0.3423 - precision: 0.3110 - recall: 0.9121 - f1_metric: 0.4550 - auc_6: 0.4974 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6946 - acc: 0.3978 - precision: 0.2705 - recall: 0.6292 - f1_metric: 0.3624 - auc_6: 0.4770 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.3696 - precision: 0.3041 - recall: 0.8358 - f1_metric: 0.4351 - auc_6: 0.5003 - val_loss: 0.6935 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.3249 - precision: 0.2979 - recall: 0.9119 - f1_metric: 0.4400 - auc_6: 0.5201 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.3242 - precision: 0.2930 - recall: 0.9099 - f1_metric: 0.4347 - auc_6: 0.4874 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.3178 - precision: 0.2899 - recall: 0.9287 - f1_metric: 0.4355 - auc_6: 0.4983 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6946 - acc: 0.3286 - precision: 0.2947 - recall: 0.9144 - f1_metric: 0.4378 - auc_6: 0.4885 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6889 - acc: 0.3882 - precision: 0.2991 - recall: 0.8226 - f1_metric: 0.4274 - auc_6: 0.5202 - val_loss: 0.7005 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5504 - precision: 0.2759 - recall: 0.3902 - f1_metric: 0.2399 - auc_6: 0.4798 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.3211 - precision: 0.2919 - recall: 0.9326 - f1_metric: 0.4396 - auc_6: 0.4975 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.3250 - precision: 0.3046 - recall: 0.9411 - f1_metric: 0.4546 - auc_6: 0.4801 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.3319 - precision: 0.3063 - recall: 0.8958 - f1_metric: 0.4487 - auc_6: 0.4766 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5982 - precision: 0.2795 - recall: 0.2263 - f1_metric: 0.2108 - auc_6: 0.4749 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3161 - precision: 0.3038 - recall: 0.9677 - f1_metric: 0.4581 - auc_6: 0.4979 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.3017 - precision: 0.2928 - recall: 0.9777 - f1_metric: 0.4437 - auc_6: 0.4951 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.3293 - precision: 0.2922 - recall: 0.9168 - f1_metric: 0.4346 - auc_6: 0.5047 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.3097 - precision: 0.2934 - recall: 0.9512 - f1_metric: 0.4421 - auc_6: 0.4939 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.3231 - precision: 0.2990 - recall: 0.8974 - f1_metric: 0.4423 - auc_6: 0.4890 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.3252 - precision: 0.3047 - recall: 0.9625 - f1_metric: 0.4569 - auc_6: 0.5095 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.3178 - precision: 0.3000 - recall: 0.9491 - f1_metric: 0.4493 - auc_6: 0.4994 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.3252 - precision: 0.3020 - recall: 0.9305 - f1_metric: 0.4515 - auc_6: 0.4988 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6872 - acc: 0.3633 - precision: 0.2832 - recall: 0.8063 - f1_metric: 0.4118 - auc_6: 0.4994 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.3218 - precision: 0.2977 - recall: 0.9655 - f1_metric: 0.4493 - auc_6: 0.5119 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_6: 0.5000\n",
            "Model 8 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6992 - acc: 0.4251 - precision: 0.2852 - recall: 0.5857 - f1_metric: 0.3543 - auc_7: 0.4466 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.5127 - precision: 0.2902 - recall: 0.4602 - f1_metric: 0.3275 - auc_7: 0.4766 - val_loss: 0.6937 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.4928 - precision: 0.3121 - recall: 0.5646 - f1_metric: 0.3689 - auc_7: 0.4899 - val_loss: 0.6903 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_7: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7017 - acc: 0.4377 - precision: 0.3129 - recall: 0.6745 - f1_metric: 0.3980 - auc_7: 0.4904 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.3433 - precision: 0.3048 - recall: 0.9083 - f1_metric: 0.4468 - auc_7: 0.4976 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6871 - acc: 0.4694 - precision: 0.2973 - recall: 0.6305 - f1_metric: 0.3760 - auc_7: 0.4969 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.3433 - precision: 0.3019 - recall: 0.8844 - f1_metric: 0.4416 - auc_7: 0.5005 - val_loss: 0.6769 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_7: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.5483 - precision: 0.3734 - recall: 0.3972 - f1_metric: 0.2714 - auc_7: 0.5097 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3217 - precision: 0.3023 - recall: 0.9476 - f1_metric: 0.4532 - auc_7: 0.4933 - val_loss: 0.6879 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_7: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6999 - acc: 0.4857 - precision: 0.2859 - recall: 0.4550 - f1_metric: 0.3101 - auc_7: 0.4806 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.4977\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.4173 - precision: 0.2933 - recall: 0.6994 - f1_metric: 0.4008 - auc_7: 0.5053 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.3027 - precision: 0.2937 - recall: 0.9795 - f1_metric: 0.4452 - auc_7: 0.4930 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.2987 - precision: 0.2955 - recall: 0.9676 - f1_metric: 0.4457 - auc_7: 0.5073 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.3037 - precision: 0.2961 - recall: 0.9776 - f1_metric: 0.4487 - auc_7: 0.4848 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6879 - acc: 0.3210 - precision: 0.2851 - recall: 0.9032 - f1_metric: 0.4250 - auc_7: 0.5120 - val_loss: 0.7041 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.3528 - precision: 0.3065 - recall: 0.8889 - f1_metric: 0.4469 - auc_7: 0.4946 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6989 - acc: 0.3201 - precision: 0.3058 - recall: 0.9786 - f1_metric: 0.4598 - auc_7: 0.5099 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.3106 - precision: 0.2993 - recall: 0.9564 - f1_metric: 0.4503 - auc_7: 0.4847 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 0.3072 - precision: 0.3059 - recall: 0.9988 - f1_metric: 0.4624 - auc_7: 0.5042 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.2962 - precision: 0.2920 - recall: 0.9859 - f1_metric: 0.4456 - auc_7: 0.4917 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6989 - acc: 0.3075 - precision: 0.3031 - recall: 0.9869 - f1_metric: 0.4588 - auc_7: 0.4846 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.3102 - precision: 0.3083 - recall: 0.9970 - f1_metric: 0.4646 - auc_7: 0.5105 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.2985 - precision: 0.2957 - recall: 0.9983 - f1_metric: 0.4501 - auc_7: 0.5021 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.2932 - precision: 0.2900 - recall: 0.9918 - f1_metric: 0.4426 - auc_7: 0.5002 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6823 - acc: 0.2823 - precision: 0.2793 - recall: 0.9989 - f1_metric: 0.4299 - auc_7: 0.4601 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7013 - acc: 0.3070 - precision: 0.3070 - recall: 0.9996 - f1_metric: 0.4628 - auc_7: 0.5084 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6999 - acc: 0.3053 - precision: 0.3053 - recall: 1.0000 - f1_metric: 0.4616 - auc_7: 0.5165 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.2954 - precision: 0.2946 - recall: 0.9977 - f1_metric: 0.4500 - auc_7: 0.4717 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.3036 - precision: 0.3022 - recall: 0.9712 - f1_metric: 0.4551 - auc_7: 0.4925 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3059 - precision: 0.3047 - recall: 0.9978 - f1_metric: 0.4606 - auc_7: 0.5119 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_7: 0.5000\n",
            "Model 9 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7043 - acc: 0.5022 - precision: 0.3248 - recall: 0.5431 - f1_metric: 0.3463 - auc_8: 0.5142 - val_loss: 0.6695 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_8: 0.4977\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6941 - acc: 0.5508 - precision: 0.2218 - recall: 0.3352 - f1_metric: 0.2389 - auc_8: 0.4982 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_8: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.4905 - precision: 0.3006 - recall: 0.5357 - f1_metric: 0.3582 - auc_8: 0.5117 - val_loss: 0.6712 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_8: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.5140 - precision: 0.3388 - recall: 0.4823 - f1_metric: 0.3282 - auc_8: 0.5153 - val_loss: 0.7004 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3415 - precision: 0.2990 - recall: 0.8683 - f1_metric: 0.4390 - auc_8: 0.4979 - val_loss: 0.7028 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.4351 - precision: 0.3091 - recall: 0.6752 - f1_metric: 0.3918 - auc_8: 0.4871 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.3585 - precision: 0.3001 - recall: 0.8652 - f1_metric: 0.4393 - auc_8: 0.5038 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7033 - acc: 0.3159 - precision: 0.2902 - recall: 0.8591 - f1_metric: 0.4277 - auc_8: 0.4705 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.3228 - precision: 0.2988 - recall: 0.9222 - f1_metric: 0.4452 - auc_8: 0.4865 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.3258 - precision: 0.2880 - recall: 0.9149 - f1_metric: 0.4322 - auc_8: 0.5029 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.3355 - precision: 0.2968 - recall: 0.8857 - f1_metric: 0.4373 - auc_8: 0.4991 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.4481 - precision: 0.3032 - recall: 0.6287 - f1_metric: 0.3922 - auc_8: 0.4963 - val_loss: 0.6908 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_8: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.5598 - precision: 0.3111 - recall: 0.3553 - f1_metric: 0.2961 - auc_8: 0.5054 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.3367 - precision: 0.3041 - recall: 0.9157 - f1_metric: 0.4494 - auc_8: 0.4977 - val_loss: 0.6996 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6883 - acc: 0.3663 - precision: 0.2897 - recall: 0.8101 - f1_metric: 0.4095 - auc_8: 0.4945 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.3071 - precision: 0.2957 - recall: 0.9728 - f1_metric: 0.4470 - auc_8: 0.4942 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.2989 - precision: 0.2929 - recall: 0.9738 - f1_metric: 0.4448 - auc_8: 0.4846 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 0.3012 - precision: 0.2988 - recall: 0.9833 - f1_metric: 0.4522 - auc_8: 0.4793 - val_loss: 0.6992 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.3521 - precision: 0.2962 - recall: 0.8573 - f1_metric: 0.4274 - auc_8: 0.5061 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.2934 - precision: 0.2885 - recall: 0.9814 - f1_metric: 0.4387 - auc_8: 0.4912 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.3001 - precision: 0.2970 - recall: 0.9918 - f1_metric: 0.4516 - auc_8: 0.5143 - val_loss: 0.6990 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3118 - precision: 0.2972 - recall: 0.9771 - f1_metric: 0.4497 - auc_8: 0.5027 - val_loss: 0.6997 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 0.3186 - precision: 0.3165 - recall: 0.9881 - f1_metric: 0.4726 - auc_8: 0.4924 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 0.3199 - precision: 0.3063 - recall: 0.9679 - f1_metric: 0.4576 - auc_8: 0.4963 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.3191 - precision: 0.3034 - recall: 0.9548 - f1_metric: 0.4526 - auc_8: 0.5008 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3047 - precision: 0.2984 - recall: 0.9909 - f1_metric: 0.4535 - auc_8: 0.5004 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.3218 - precision: 0.2933 - recall: 0.9367 - f1_metric: 0.4385 - auc_8: 0.4950 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6983 - acc: 0.3579 - precision: 0.3097 - recall: 0.8835 - f1_metric: 0.4501 - auc_8: 0.5233 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.3241 - precision: 0.3029 - recall: 0.9321 - f1_metric: 0.4505 - auc_8: 0.4818 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.3066 - precision: 0.2965 - recall: 0.9469 - f1_metric: 0.4468 - auc_8: 0.4787 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_8: 0.5000\n",
            "Model 10 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 9ms/step - loss: 0.7023 - acc: 0.4552 - precision: 0.2871 - recall: 0.5620 - f1_metric: 0.3422 - auc_9: 0.4786 - val_loss: 0.6759 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7040 - acc: 0.4963 - precision: 0.2919 - recall: 0.4824 - f1_metric: 0.3141 - auc_9: 0.4830 - val_loss: 0.6827 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5325 - precision: 0.2802 - recall: 0.3908 - f1_metric: 0.2883 - auc_9: 0.4794 - val_loss: 0.7082 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.4260 - precision: 0.3145 - recall: 0.7323 - f1_metric: 0.4084 - auc_9: 0.5002 - val_loss: 0.7085 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.3693 - precision: 0.3072 - recall: 0.8732 - f1_metric: 0.4350 - auc_9: 0.5065 - val_loss: 0.7041 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.4272 - precision: 0.3069 - recall: 0.6871 - f1_metric: 0.4049 - auc_9: 0.4894 - val_loss: 0.6860 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.5362 - precision: 0.3348 - recall: 0.4890 - f1_metric: 0.3322 - auc_9: 0.5056 - val_loss: 0.6832 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6917 - acc: 0.5500 - precision: 0.3122 - recall: 0.3839 - f1_metric: 0.2948 - auc_9: 0.4996 - val_loss: 0.7124 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3845 - precision: 0.3130 - recall: 0.8288 - f1_metric: 0.4216 - auc_9: 0.5257 - val_loss: 0.6904 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7036 - acc: 0.3786 - precision: 0.2917 - recall: 0.7574 - f1_metric: 0.4059 - auc_9: 0.4862 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.5121 - precision: 0.3053 - recall: 0.4657 - f1_metric: 0.3298 - auc_9: 0.4957 - val_loss: 0.7060 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6999 - acc: 0.3705 - precision: 0.3076 - recall: 0.8462 - f1_metric: 0.4360 - auc_9: 0.4905 - val_loss: 0.7038 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6893 - acc: 0.4760 - precision: 0.2893 - recall: 0.4997 - f1_metric: 0.3232 - auc_9: 0.4810 - val_loss: 0.7237 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6908 - acc: 0.3337 - precision: 0.2894 - recall: 0.8926 - f1_metric: 0.4265 - auc_9: 0.4973 - val_loss: 0.7003 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.4977\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7034 - acc: 0.3258 - precision: 0.3074 - recall: 0.9426 - f1_metric: 0.4585 - auc_9: 0.4801 - val_loss: 0.6908 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.4941 - precision: 0.3068 - recall: 0.5187 - f1_metric: 0.3544 - auc_9: 0.5046 - val_loss: 0.6930 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.4162 - precision: 0.3018 - recall: 0.7181 - f1_metric: 0.4118 - auc_9: 0.4903 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.4144 - precision: 0.2947 - recall: 0.6783 - f1_metric: 0.3995 - auc_9: 0.4798 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5916 - precision: 0.2904 - recall: 0.2520 - f1_metric: 0.2549 - auc_9: 0.4943 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.4921 - precision: 0.3095 - recall: 0.5759 - f1_metric: 0.3878 - auc_9: 0.5016 - val_loss: 0.6928 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_9: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3972 - precision: 0.2809 - recall: 0.6885 - f1_metric: 0.3886 - auc_9: 0.5052 - val_loss: 0.6943 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3093 - precision: 0.3014 - recall: 0.9694 - f1_metric: 0.4544 - auc_9: 0.4739 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6862 - acc: 0.4351 - precision: 0.2699 - recall: 0.6090 - f1_metric: 0.3262 - auc_9: 0.4879 - val_loss: 0.6954 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.3210 - precision: 0.2823 - recall: 0.8845 - f1_metric: 0.4211 - auc_9: 0.4968 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3059 - precision: 0.2980 - recall: 0.9751 - f1_metric: 0.4507 - auc_9: 0.5000 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7050 - acc: 0.3154 - precision: 0.3116 - recall: 0.9865 - f1_metric: 0.4674 - auc_9: 0.4975 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3009 - precision: 0.2969 - recall: 0.9857 - f1_metric: 0.4506 - auc_9: 0.4895 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.2996 - precision: 0.2980 - recall: 0.9924 - f1_metric: 0.4525 - auc_9: 0.5124 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.3091 - precision: 0.3000 - recall: 0.9748 - f1_metric: 0.4529 - auc_9: 0.4977 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.3070 - precision: 0.2885 - recall: 0.9490 - f1_metric: 0.4360 - auc_9: 0.4931 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_9: 0.5000\n",
            "Model 11 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.7010 - acc: 0.4452 - precision: 0.2966 - recall: 0.6195 - f1_metric: 0.3745 - auc_10: 0.4928 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7046 - acc: 0.4196 - precision: 0.2976 - recall: 0.6973 - f1_metric: 0.3896 - auc_10: 0.4884 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.4763 - precision: 0.2730 - recall: 0.4349 - f1_metric: 0.3173 - auc_10: 0.4659 - val_loss: 0.7073 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 0.4372 - precision: 0.3134 - recall: 0.7132 - f1_metric: 0.4172 - auc_10: 0.5054 - val_loss: 0.6788 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_10: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.6226 - precision: 0.2927 - recall: 0.1991 - f1_metric: 0.2077 - auc_10: 0.5122 - val_loss: 0.7065 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.3188 - precision: 0.2997 - recall: 0.9461 - f1_metric: 0.4494 - auc_10: 0.5030 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_10: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7113 - acc: 0.3884 - precision: 0.3266 - recall: 0.8307 - f1_metric: 0.4566 - auc_10: 0.4996 - val_loss: 0.6912 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_10: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6908 - acc: 0.5938 - precision: 0.3008 - recall: 0.2995 - f1_metric: 0.2865 - auc_10: 0.4949 - val_loss: 0.6923 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_10: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.3975 - precision: 0.3095 - recall: 0.7687 - f1_metric: 0.4276 - auc_10: 0.4868 - val_loss: 0.6899 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_10: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6887 - acc: 0.6056 - precision: 0.2767 - recall: 0.2342 - f1_metric: 0.2286 - auc_10: 0.4805 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.4473 - precision: 0.3108 - recall: 0.6987 - f1_metric: 0.4090 - auc_10: 0.5087 - val_loss: 0.6933 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3962 - precision: 0.2957 - recall: 0.7337 - f1_metric: 0.4033 - auc_10: 0.4985 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.4067 - precision: 0.2928 - recall: 0.7012 - f1_metric: 0.4028 - auc_10: 0.4964 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.3483 - precision: 0.2995 - recall: 0.8544 - f1_metric: 0.4372 - auc_10: 0.4974 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.3589 - precision: 0.2974 - recall: 0.8879 - f1_metric: 0.4353 - auc_10: 0.4996 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 0.2970 - precision: 0.2923 - recall: 0.9905 - f1_metric: 0.4452 - auc_10: 0.4991 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7008 - acc: 0.3286 - precision: 0.3061 - recall: 0.9404 - f1_metric: 0.4487 - auc_10: 0.4951 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.3066 - precision: 0.2997 - recall: 0.9835 - f1_metric: 0.4523 - auc_10: 0.4758 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.3046 - precision: 0.2995 - recall: 0.9871 - f1_metric: 0.4537 - auc_10: 0.5107 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.3060 - precision: 0.3008 - recall: 0.9925 - f1_metric: 0.4547 - auc_10: 0.4868 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.2952 - precision: 0.2906 - recall: 0.9860 - f1_metric: 0.4432 - auc_10: 0.4998 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6835 - acc: 0.2829 - precision: 0.2799 - recall: 0.9899 - f1_metric: 0.4289 - auc_10: 0.4922 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.2962 - precision: 0.2921 - recall: 0.9782 - f1_metric: 0.4435 - auc_10: 0.4920 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.2984 - precision: 0.2961 - recall: 0.9962 - f1_metric: 0.4525 - auc_10: 0.4907 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.2967 - precision: 0.2956 - recall: 0.9956 - f1_metric: 0.4501 - auc_10: 0.4985 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.2949 - precision: 0.2932 - recall: 0.9884 - f1_metric: 0.4466 - auc_10: 0.4998 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3040 - precision: 0.3021 - recall: 0.9887 - f1_metric: 0.4574 - auc_10: 0.5048 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6856 - acc: 0.2834 - precision: 0.2833 - recall: 1.0000 - f1_metric: 0.4351 - auc_10: 0.4906 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.2953 - precision: 0.2946 - recall: 0.9997 - f1_metric: 0.4479 - auc_10: 0.5002 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.2988 - precision: 0.2987 - recall: 1.0000 - f1_metric: 0.4546 - auc_10: 0.4966 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_10: 0.5000\n",
            "Model 12 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6996 - acc: 0.4786 - precision: 0.2888 - recall: 0.5439 - f1_metric: 0.3341 - auc_11: 0.4825 - val_loss: 0.6847 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6887 - acc: 0.5819 - precision: 0.2572 - recall: 0.2993 - f1_metric: 0.2189 - auc_11: 0.5166 - val_loss: 0.6921 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7062 - acc: 0.3846 - precision: 0.3229 - recall: 0.8608 - f1_metric: 0.4583 - auc_11: 0.5033 - val_loss: 0.6609 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.5891 - precision: 0.2201 - recall: 0.2806 - f1_metric: 0.1747 - auc_11: 0.5073 - val_loss: 0.6888 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5956 - precision: 0.2571 - recall: 0.2568 - f1_metric: 0.2326 - auc_11: 0.4704 - val_loss: 0.6954 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7008 - acc: 0.3355 - precision: 0.3047 - recall: 0.9231 - f1_metric: 0.4498 - auc_11: 0.4812 - val_loss: 0.6870 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.4557 - precision: 0.2989 - recall: 0.5848 - f1_metric: 0.3741 - auc_11: 0.4997 - val_loss: 0.7039 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7021 - acc: 0.3491 - precision: 0.3073 - recall: 0.8916 - f1_metric: 0.4481 - auc_11: 0.5075 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.4516 - precision: 0.3024 - recall: 0.6248 - f1_metric: 0.3918 - auc_11: 0.4977 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3515 - precision: 0.2988 - recall: 0.8681 - f1_metric: 0.4403 - auc_11: 0.4902 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.3840 - precision: 0.2827 - recall: 0.7424 - f1_metric: 0.3957 - auc_11: 0.4809 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.3556 - precision: 0.3046 - recall: 0.9213 - f1_metric: 0.4515 - auc_11: 0.4970 - val_loss: 0.6926 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.5336 - precision: 0.3012 - recall: 0.4754 - f1_metric: 0.3478 - auc_11: 0.5006 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.3050 - precision: 0.2996 - recall: 0.9857 - f1_metric: 0.4548 - auc_11: 0.4954 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3370 - precision: 0.2970 - recall: 0.8843 - f1_metric: 0.4333 - auc_11: 0.4971 - val_loss: 0.6909 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.4977\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.4452 - precision: 0.3078 - recall: 0.6378 - f1_metric: 0.4022 - auc_11: 0.5050 - val_loss: 0.6896 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.5498 - precision: 0.2922 - recall: 0.3482 - f1_metric: 0.2988 - auc_11: 0.4829 - val_loss: 0.6923 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.3311 - precision: 0.2996 - recall: 0.9282 - f1_metric: 0.4454 - auc_11: 0.4934 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.4084 - precision: 0.2911 - recall: 0.7201 - f1_metric: 0.4030 - auc_11: 0.4997 - val_loss: 0.7008 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6995 - acc: 0.3515 - precision: 0.3053 - recall: 0.8914 - f1_metric: 0.4403 - auc_11: 0.5200 - val_loss: 0.6861 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.5397 - precision: 0.3077 - recall: 0.4478 - f1_metric: 0.3386 - auc_11: 0.5051 - val_loss: 0.6997 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.3449 - precision: 0.3035 - recall: 0.9007 - f1_metric: 0.4463 - auc_11: 0.5131 - val_loss: 0.6901 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.4801 - precision: 0.3240 - recall: 0.6062 - f1_metric: 0.3877 - auc_11: 0.5100 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6953 - acc: 0.4531 - precision: 0.3018 - recall: 0.6253 - f1_metric: 0.3910 - auc_11: 0.5039 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7018 - acc: 0.3806 - precision: 0.3094 - recall: 0.8088 - f1_metric: 0.4405 - auc_11: 0.4965 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6862 - acc: 0.4847 - precision: 0.2361 - recall: 0.4326 - f1_metric: 0.2740 - auc_11: 0.4742 - val_loss: 0.6997 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7052 - acc: 0.3315 - precision: 0.3130 - recall: 0.9526 - f1_metric: 0.4642 - auc_11: 0.4831 - val_loss: 0.6900 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_11: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.5355 - precision: 0.3156 - recall: 0.4163 - f1_metric: 0.3357 - auc_11: 0.4986 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 0.3657 - precision: 0.2982 - recall: 0.7879 - f1_metric: 0.4234 - auc_11: 0.4892 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.4271 - precision: 0.3048 - recall: 0.7322 - f1_metric: 0.4196 - auc_11: 0.5036 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_11: 0.5000\n",
            "Model 13 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6955 - acc: 0.5547 - precision: 0.2380 - recall: 0.4046 - f1_metric: 0.2521 - auc_12: 0.5083 - val_loss: 0.7003 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.4058 - precision: 0.2990 - recall: 0.7020 - f1_metric: 0.4041 - auc_12: 0.4554 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.5130 - precision: 0.2819 - recall: 0.4583 - f1_metric: 0.3076 - auc_12: 0.4867 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6858 - acc: 0.4613 - precision: 0.2581 - recall: 0.5604 - f1_metric: 0.3179 - auc_12: 0.4910 - val_loss: 0.7181 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.3677 - precision: 0.2989 - recall: 0.8249 - f1_metric: 0.4239 - auc_12: 0.4908 - val_loss: 0.6870 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.4800 - precision: 0.2744 - recall: 0.5194 - f1_metric: 0.3113 - auc_12: 0.4758 - val_loss: 0.6922 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.6521 - precision: 0.2731 - recall: 0.1873 - f1_metric: 0.1818 - auc_12: 0.4943 - val_loss: 0.7091 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6985 - acc: 0.3162 - precision: 0.3029 - recall: 0.9632 - f1_metric: 0.4554 - auc_12: 0.5231 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.4918 - precision: 0.2894 - recall: 0.5440 - f1_metric: 0.3090 - auc_12: 0.4801 - val_loss: 0.7045 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.3430 - precision: 0.3020 - recall: 0.8956 - f1_metric: 0.4369 - auc_12: 0.4981 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.4088 - precision: 0.2783 - recall: 0.6602 - f1_metric: 0.3755 - auc_12: 0.4911 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.4345 - precision: 0.2839 - recall: 0.6000 - f1_metric: 0.3686 - auc_12: 0.4721 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.3211 - precision: 0.2967 - recall: 0.9191 - f1_metric: 0.4422 - auc_12: 0.4734 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6880 - acc: 0.4879 - precision: 0.2630 - recall: 0.4485 - f1_metric: 0.2880 - auc_12: 0.4916 - val_loss: 0.6999 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7034 - acc: 0.3186 - precision: 0.3098 - recall: 0.9772 - f1_metric: 0.4624 - auc_12: 0.4950 - val_loss: 0.6919 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.4768 - precision: 0.2991 - recall: 0.5771 - f1_metric: 0.3812 - auc_12: 0.4954 - val_loss: 0.7000 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.2975 - precision: 0.2952 - recall: 0.9827 - f1_metric: 0.4483 - auc_12: 0.4768 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3599 - precision: 0.3069 - recall: 0.8954 - f1_metric: 0.4452 - auc_12: 0.5146 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.4740 - precision: 0.2837 - recall: 0.5341 - f1_metric: 0.3416 - auc_12: 0.4991 - val_loss: 0.6876 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.4930 - precision: 0.3071 - recall: 0.5248 - f1_metric: 0.3376 - auc_12: 0.4899 - val_loss: 0.6912 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_12: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.3545 - precision: 0.2933 - recall: 0.8254 - f1_metric: 0.4195 - auc_12: 0.4899 - val_loss: 0.7010 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.3208 - precision: 0.3042 - recall: 0.9632 - f1_metric: 0.4549 - auc_12: 0.4946 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.4849 - precision: 0.2814 - recall: 0.5141 - f1_metric: 0.3445 - auc_12: 0.5056 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7046 - acc: 0.3261 - precision: 0.3118 - recall: 0.9593 - f1_metric: 0.4639 - auc_12: 0.4739 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.3776 - precision: 0.3041 - recall: 0.8354 - f1_metric: 0.4331 - auc_12: 0.4985 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.3163 - precision: 0.2991 - recall: 0.9496 - f1_metric: 0.4471 - auc_12: 0.5135 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.3773 - precision: 0.2920 - recall: 0.8005 - f1_metric: 0.4093 - auc_12: 0.4887 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.3038 - precision: 0.2957 - recall: 0.9813 - f1_metric: 0.4480 - auc_12: 0.5246 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.3376 - precision: 0.2998 - recall: 0.9225 - f1_metric: 0.4474 - auc_12: 0.5034 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3185 - precision: 0.2985 - recall: 0.9471 - f1_metric: 0.4475 - auc_12: 0.4985 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_12: 0.5000\n",
            "Model 14 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7004 - acc: 0.4287 - precision: 0.3007 - recall: 0.7009 - f1_metric: 0.3890 - auc_13: 0.4956 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.4733 - precision: 0.2990 - recall: 0.5976 - f1_metric: 0.3811 - auc_13: 0.4884 - val_loss: 0.7152 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.3962 - precision: 0.3131 - recall: 0.7490 - f1_metric: 0.3910 - auc_13: 0.4948 - val_loss: 0.6909 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7016 - acc: 0.4197 - precision: 0.3099 - recall: 0.7183 - f1_metric: 0.4092 - auc_13: 0.5000 - val_loss: 0.6902 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6947 - acc: 0.5763 - precision: 0.3015 - recall: 0.3446 - f1_metric: 0.2815 - auc_13: 0.5056 - val_loss: 0.7161 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.3959 - precision: 0.2923 - recall: 0.7313 - f1_metric: 0.3986 - auc_13: 0.4703 - val_loss: 0.7006 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7029 - acc: 0.3602 - precision: 0.3105 - recall: 0.8774 - f1_metric: 0.4485 - auc_13: 0.5082 - val_loss: 0.6881 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.4270 - precision: 0.2897 - recall: 0.6784 - f1_metric: 0.3842 - auc_13: 0.4992 - val_loss: 0.6872 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.4506 - precision: 0.3044 - recall: 0.6208 - f1_metric: 0.3862 - auc_13: 0.5067 - val_loss: 0.6917 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7044 - acc: 0.3922 - precision: 0.3239 - recall: 0.8044 - f1_metric: 0.4385 - auc_13: 0.5068 - val_loss: 0.6728 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.5789 - precision: 0.3352 - recall: 0.3755 - f1_metric: 0.3227 - auc_13: 0.5008 - val_loss: 0.7147 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6910 - acc: 0.3265 - precision: 0.2916 - recall: 0.8986 - f1_metric: 0.4241 - auc_13: 0.4859 - val_loss: 0.7042 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6944 - acc: 0.3285 - precision: 0.2999 - recall: 0.9491 - f1_metric: 0.4502 - auc_13: 0.4991 - val_loss: 0.6991 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.3974 - precision: 0.2947 - recall: 0.7235 - f1_metric: 0.3832 - auc_13: 0.4759 - val_loss: 0.6875 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.6042 - precision: 0.3279 - recall: 0.2698 - f1_metric: 0.2317 - auc_13: 0.5158 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.3998 - precision: 0.3005 - recall: 0.7287 - f1_metric: 0.4108 - auc_13: 0.4908 - val_loss: 0.6865 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6871 - acc: 0.6234 - precision: 0.2333 - recall: 0.2089 - f1_metric: 0.1593 - auc_13: 0.4823 - val_loss: 0.7015 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.4774 - precision: 0.3067 - recall: 0.5805 - f1_metric: 0.3724 - auc_13: 0.5076 - val_loss: 0.7139 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3652 - precision: 0.3032 - recall: 0.8208 - f1_metric: 0.4315 - auc_13: 0.4961 - val_loss: 0.6912 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 0.5383 - precision: 0.3077 - recall: 0.4468 - f1_metric: 0.3105 - auc_13: 0.5044 - val_loss: 0.7089 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.3492 - precision: 0.3022 - recall: 0.8660 - f1_metric: 0.4232 - auc_13: 0.4900 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6877 - acc: 0.5623 - precision: 0.2642 - recall: 0.3023 - f1_metric: 0.2274 - auc_13: 0.4865 - val_loss: 0.7129 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3412 - precision: 0.2998 - recall: 0.8963 - f1_metric: 0.4392 - auc_13: 0.4814 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_13: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.6351 - precision: 0.2029 - recall: 0.1208 - f1_metric: 0.1371 - auc_13: 0.4853 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3098 - precision: 0.2992 - recall: 0.9782 - f1_metric: 0.4500 - auc_13: 0.5034 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.4512 - precision: 0.3184 - recall: 0.6661 - f1_metric: 0.3791 - auc_13: 0.4886 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3197 - precision: 0.2976 - recall: 0.9523 - f1_metric: 0.4476 - auc_13: 0.5215 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6873 - acc: 0.4465 - precision: 0.2586 - recall: 0.6346 - f1_metric: 0.3375 - auc_13: 0.4911 - val_loss: 0.6992 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.3291 - precision: 0.2912 - recall: 0.9008 - f1_metric: 0.4315 - auc_13: 0.4858 - val_loss: 0.6988 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3094 - precision: 0.2964 - recall: 0.9613 - f1_metric: 0.4467 - auc_13: 0.4925 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_13: 0.5000\n",
            "Model 15 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.7043 - acc: 0.5128 - precision: 0.2797 - recall: 0.4523 - f1_metric: 0.2843 - auc_14: 0.4912 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.3902 - precision: 0.2868 - recall: 0.6927 - f1_metric: 0.3941 - auc_14: 0.4469 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.5610 - precision: 0.3036 - recall: 0.4333 - f1_metric: 0.3096 - auc_14: 0.5055 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.3802 - precision: 0.2882 - recall: 0.7511 - f1_metric: 0.3904 - auc_14: 0.4841 - val_loss: 0.7122 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3509 - precision: 0.3085 - recall: 0.8883 - f1_metric: 0.4410 - auc_14: 0.4897 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.3054 - precision: 0.3003 - recall: 0.9901 - f1_metric: 0.4549 - auc_14: 0.5067 - val_loss: 0.6994 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.3016 - precision: 0.2927 - recall: 0.9735 - f1_metric: 0.4417 - auc_14: 0.4992 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7017 - acc: 0.3107 - precision: 0.3076 - recall: 0.9942 - f1_metric: 0.4645 - auc_14: 0.4763 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 0.4069 - precision: 0.3024 - recall: 0.7513 - f1_metric: 0.3876 - auc_14: 0.4977 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 0.3253 - precision: 0.2982 - recall: 0.9272 - f1_metric: 0.4424 - auc_14: 0.4860 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.3123 - precision: 0.3008 - recall: 0.9619 - f1_metric: 0.4541 - auc_14: 0.4911 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 0.3220 - precision: 0.3069 - recall: 0.9695 - f1_metric: 0.4613 - auc_14: 0.5077 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3293 - precision: 0.2912 - recall: 0.8919 - f1_metric: 0.4324 - auc_14: 0.4867 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6944 - acc: 0.4751 - precision: 0.3111 - recall: 0.6081 - f1_metric: 0.3680 - auc_14: 0.5073 - val_loss: 0.6990 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.3620 - precision: 0.2941 - recall: 0.7960 - f1_metric: 0.4209 - auc_14: 0.4846 - val_loss: 0.6898 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_14: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.4688 - precision: 0.3068 - recall: 0.5752 - f1_metric: 0.3570 - auc_14: 0.4900 - val_loss: 0.7003 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.3279 - precision: 0.2994 - recall: 0.9333 - f1_metric: 0.4439 - auc_14: 0.5146 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6841 - acc: 0.2916 - precision: 0.2804 - recall: 0.9741 - f1_metric: 0.4284 - auc_14: 0.4941 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.2983 - precision: 0.2913 - recall: 0.9861 - f1_metric: 0.4446 - auc_14: 0.5038 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7024 - acc: 0.3096 - precision: 0.3065 - recall: 0.9804 - f1_metric: 0.4588 - auc_14: 0.5008 - val_loss: 0.6988 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.3216 - precision: 0.2899 - recall: 0.9050 - f1_metric: 0.4338 - auc_14: 0.4826 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6903 - acc: 0.3046 - precision: 0.2897 - recall: 0.9600 - f1_metric: 0.4406 - auc_14: 0.5000 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6995 - acc: 0.3080 - precision: 0.3048 - recall: 0.9930 - f1_metric: 0.4600 - auc_14: 0.5028 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6953 - acc: 0.3021 - precision: 0.2972 - recall: 0.9836 - f1_metric: 0.4514 - auc_14: 0.4974 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3040 - precision: 0.3034 - recall: 0.9982 - f1_metric: 0.4609 - auc_14: 0.5097 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.3120 - precision: 0.3107 - recall: 0.9960 - f1_metric: 0.4664 - auc_14: 0.4959 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3061 - precision: 0.2982 - recall: 0.9778 - f1_metric: 0.4504 - auc_14: 0.4988 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.2988 - precision: 0.2921 - recall: 0.9826 - f1_metric: 0.4461 - auc_14: 0.4980 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.3063 - precision: 0.2988 - recall: 0.9950 - f1_metric: 0.4537 - auc_14: 0.5059 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.3078 - precision: 0.2996 - recall: 0.9833 - f1_metric: 0.4511 - auc_14: 0.5052 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_14: 0.5000\n",
            "Model 16 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7005 - acc: 0.4149 - precision: 0.3097 - recall: 0.7001 - f1_metric: 0.4102 - auc_15: 0.4681 - val_loss: 0.6938 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.5512 - precision: 0.2202 - recall: 0.3572 - f1_metric: 0.2519 - auc_15: 0.4912 - val_loss: 0.7256 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7007 - acc: 0.3682 - precision: 0.3120 - recall: 0.8685 - f1_metric: 0.4423 - auc_15: 0.4913 - val_loss: 0.6801 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_15: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7009 - acc: 0.5202 - precision: 0.2934 - recall: 0.4812 - f1_metric: 0.3104 - auc_15: 0.5116 - val_loss: 0.6779 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_15: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.6625 - precision: 0.2011 - recall: 0.1357 - f1_metric: 0.1351 - auc_15: 0.5017 - val_loss: 0.7204 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6947 - acc: 0.3775 - precision: 0.3007 - recall: 0.8122 - f1_metric: 0.4167 - auc_15: 0.4795 - val_loss: 0.7016 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.3578 - precision: 0.2978 - recall: 0.8511 - f1_metric: 0.4281 - auc_15: 0.5040 - val_loss: 0.7008 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.3913 - precision: 0.2879 - recall: 0.7384 - f1_metric: 0.3919 - auc_15: 0.4602 - val_loss: 0.6931 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_15: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.4337 - precision: 0.3021 - recall: 0.6651 - f1_metric: 0.3985 - auc_15: 0.4897 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.3295 - precision: 0.2998 - recall: 0.9055 - f1_metric: 0.4430 - auc_15: 0.4806 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.3537 - precision: 0.2877 - recall: 0.8242 - f1_metric: 0.4202 - auc_15: 0.4942 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.3391 - precision: 0.3046 - recall: 0.8951 - f1_metric: 0.4415 - auc_15: 0.4844 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7060 - acc: 0.3152 - precision: 0.3117 - recall: 0.9811 - f1_metric: 0.4666 - auc_15: 0.4711 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6917 - acc: 0.3356 - precision: 0.2946 - recall: 0.8938 - f1_metric: 0.4300 - auc_15: 0.5161 - val_loss: 0.7051 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6872 - acc: 0.4881 - precision: 0.2932 - recall: 0.5315 - f1_metric: 0.2970 - auc_15: 0.4955 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.3114 - precision: 0.3019 - recall: 0.9749 - f1_metric: 0.4567 - auc_15: 0.5082 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.3134 - precision: 0.2956 - recall: 0.9553 - f1_metric: 0.4441 - auc_15: 0.4943 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7017 - acc: 0.3132 - precision: 0.3090 - recall: 0.9969 - f1_metric: 0.4663 - auc_15: 0.4891 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6892 - acc: 0.3112 - precision: 0.2887 - recall: 0.9518 - f1_metric: 0.4382 - auc_15: 0.5069 - val_loss: 0.7041 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.3030 - precision: 0.3000 - recall: 0.9907 - f1_metric: 0.4553 - auc_15: 0.4606 - val_loss: 0.6996 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.3108 - precision: 0.3038 - recall: 0.9830 - f1_metric: 0.4572 - auc_15: 0.4901 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.3512 - precision: 0.2925 - recall: 0.8391 - f1_metric: 0.4223 - auc_15: 0.4983 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6985 - acc: 0.3119 - precision: 0.3019 - recall: 0.9688 - f1_metric: 0.4509 - auc_15: 0.4972 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.3300 - precision: 0.3011 - recall: 0.9467 - f1_metric: 0.4486 - auc_15: 0.5030 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3311 - precision: 0.2976 - recall: 0.9324 - f1_metric: 0.4446 - auc_15: 0.5017 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.4292 - precision: 0.2945 - recall: 0.6758 - f1_metric: 0.3912 - auc_15: 0.4757 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_15: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.3426 - precision: 0.3070 - recall: 0.8877 - f1_metric: 0.4409 - auc_15: 0.4882 - val_loss: 0.6930 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_15: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.3228 - precision: 0.3089 - recall: 0.9343 - f1_metric: 0.4476 - auc_15: 0.4891 - val_loss: 0.6938 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.3491 - precision: 0.2752 - recall: 0.8022 - f1_metric: 0.3881 - auc_15: 0.4964 - val_loss: 0.6943 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.2925 - precision: 0.2925 - recall: 0.9960 - f1_metric: 0.4457 - auc_15: 0.5015 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_15: 0.5000\n",
            "Model 17 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6967 - acc: 0.5340 - precision: 0.1823 - recall: 0.3975 - f1_metric: 0.2217 - auc_16: 0.4956 - val_loss: 0.7024 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6894 - acc: 0.4649 - precision: 0.2891 - recall: 0.5705 - f1_metric: 0.3422 - auc_16: 0.4822 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.3922 - precision: 0.3013 - recall: 0.7930 - f1_metric: 0.4277 - auc_16: 0.5013 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6909 - acc: 0.5231 - precision: 0.2709 - recall: 0.4579 - f1_metric: 0.3137 - auc_16: 0.4737 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.3741 - precision: 0.2993 - recall: 0.7867 - f1_metric: 0.4212 - auc_16: 0.4947 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7008 - acc: 0.3834 - precision: 0.3003 - recall: 0.7716 - f1_metric: 0.4168 - auc_16: 0.4950 - val_loss: 0.6877 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7021 - acc: 0.3576 - precision: 0.3041 - recall: 0.8437 - f1_metric: 0.4295 - auc_16: 0.4769 - val_loss: 0.6815 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 0.5448 - precision: 0.2793 - recall: 0.3675 - f1_metric: 0.2549 - auc_16: 0.4860 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.3766 - precision: 0.2967 - recall: 0.8058 - f1_metric: 0.4275 - auc_16: 0.5110 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.4913 - precision: 0.2793 - recall: 0.5473 - f1_metric: 0.3342 - auc_16: 0.5032 - val_loss: 0.7143 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.4106 - precision: 0.2943 - recall: 0.7468 - f1_metric: 0.3872 - auc_16: 0.4841 - val_loss: 0.7060 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6930 - acc: 0.3137 - precision: 0.2929 - recall: 0.9425 - f1_metric: 0.4390 - auc_16: 0.4855 - val_loss: 0.7009 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7009 - acc: 0.3292 - precision: 0.3075 - recall: 0.9448 - f1_metric: 0.4591 - auc_16: 0.5125 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6848 - acc: 0.6052 - precision: 0.2378 - recall: 0.2452 - f1_metric: 0.1931 - auc_16: 0.5083 - val_loss: 0.7000 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.3985 - precision: 0.2915 - recall: 0.7404 - f1_metric: 0.4014 - auc_16: 0.5127 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5138 - precision: 0.3002 - recall: 0.4739 - f1_metric: 0.3338 - auc_16: 0.5068 - val_loss: 0.6813 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.5766 - precision: 0.2564 - recall: 0.3297 - f1_metric: 0.2318 - auc_16: 0.4849 - val_loss: 0.6903 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6858 - acc: 0.6281 - precision: 0.2352 - recall: 0.1693 - f1_metric: 0.1776 - auc_16: 0.4816 - val_loss: 0.7052 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3130 - precision: 0.3033 - recall: 0.9709 - f1_metric: 0.4559 - auc_16: 0.4877 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.4147 - precision: 0.3009 - recall: 0.6940 - f1_metric: 0.4028 - auc_16: 0.5009 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.4977\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.3919 - precision: 0.2856 - recall: 0.7253 - f1_metric: 0.3914 - auc_16: 0.4893 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.2953 - precision: 0.2953 - recall: 1.0000 - f1_metric: 0.4495 - auc_16: 0.4701 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.2899 - precision: 0.2898 - recall: 0.9991 - f1_metric: 0.4416 - auc_16: 0.4986 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.3057 - precision: 0.2982 - recall: 0.9780 - f1_metric: 0.4507 - auc_16: 0.4895 - val_loss: 0.6954 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.3075 - precision: 0.3075 - recall: 1.0000 - f1_metric: 0.4647 - auc_16: 0.4713 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.2962 - precision: 0.2959 - recall: 0.9988 - f1_metric: 0.4521 - auc_16: 0.5218 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.2972 - precision: 0.2972 - recall: 1.0000 - f1_metric: 0.4521 - auc_16: 0.4748 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3044 - precision: 0.2992 - recall: 0.9860 - f1_metric: 0.4522 - auc_16: 0.4931 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5643 - precision: 0.3144 - recall: 0.3877 - f1_metric: 0.3063 - auc_16: 0.4884 - val_loss: 0.6928 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_16: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 0.3888 - precision: 0.2977 - recall: 0.7904 - f1_metric: 0.3939 - auc_16: 0.5082 - val_loss: 0.6976 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_16: 0.5000\n",
            "Model 18 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6966 - acc: 0.4975 - precision: 0.2578 - recall: 0.4646 - f1_metric: 0.2922 - auc_17: 0.4877 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.4722 - precision: 0.2873 - recall: 0.4929 - f1_metric: 0.3082 - auc_17: 0.4689 - val_loss: 0.6753 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_17: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.5755 - precision: 0.3007 - recall: 0.3163 - f1_metric: 0.2416 - auc_17: 0.4992 - val_loss: 0.7025 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.4413 - precision: 0.2867 - recall: 0.5916 - f1_metric: 0.3578 - auc_17: 0.4863 - val_loss: 0.7005 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6905 - acc: 0.4649 - precision: 0.2761 - recall: 0.5126 - f1_metric: 0.3217 - auc_17: 0.4732 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.4390 - precision: 0.2825 - recall: 0.5882 - f1_metric: 0.3460 - auc_17: 0.4865 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7045 - acc: 0.3474 - precision: 0.3089 - recall: 0.8808 - f1_metric: 0.4455 - auc_17: 0.4979 - val_loss: 0.6840 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_17: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.5841 - precision: 0.3274 - recall: 0.3045 - f1_metric: 0.2585 - auc_17: 0.4995 - val_loss: 0.6991 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.4480 - precision: 0.2641 - recall: 0.5645 - f1_metric: 0.3234 - auc_17: 0.4842 - val_loss: 0.6938 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6918 - acc: 0.4077 - precision: 0.2940 - recall: 0.7228 - f1_metric: 0.4060 - auc_17: 0.4903 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.3262 - precision: 0.2951 - recall: 0.9020 - f1_metric: 0.4363 - auc_17: 0.5150 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.3198 - precision: 0.3070 - recall: 0.9563 - f1_metric: 0.4589 - auc_17: 0.4919 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5500 - precision: 0.2892 - recall: 0.3812 - f1_metric: 0.3005 - auc_17: 0.4976 - val_loss: 0.6931 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_17: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.4764 - precision: 0.3063 - recall: 0.6098 - f1_metric: 0.3961 - auc_17: 0.5096 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.3350 - precision: 0.2892 - recall: 0.8565 - f1_metric: 0.4251 - auc_17: 0.4722 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6913 - acc: 0.4595 - precision: 0.2696 - recall: 0.5519 - f1_metric: 0.3332 - auc_17: 0.4947 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.3167 - precision: 0.3047 - recall: 0.9577 - f1_metric: 0.4566 - auc_17: 0.4909 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3802 - precision: 0.2946 - recall: 0.7575 - f1_metric: 0.4063 - auc_17: 0.4924 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.4310 - precision: 0.2739 - recall: 0.5723 - f1_metric: 0.3134 - auc_17: 0.4596 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.3008 - precision: 0.2912 - recall: 0.9751 - f1_metric: 0.4425 - auc_17: 0.4858 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.3044 - precision: 0.2977 - recall: 0.9780 - f1_metric: 0.4508 - auc_17: 0.5085 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7054 - acc: 0.3127 - precision: 0.3126 - recall: 0.9999 - f1_metric: 0.4713 - auc_17: 0.4768 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3168 - precision: 0.3030 - recall: 0.9577 - f1_metric: 0.4542 - auc_17: 0.5035 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6877 - acc: 0.3732 - precision: 0.2867 - recall: 0.7803 - f1_metric: 0.4112 - auc_17: 0.4660 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.3525 - precision: 0.2958 - recall: 0.8644 - f1_metric: 0.4353 - auc_17: 0.5205 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6860 - acc: 0.3281 - precision: 0.2845 - recall: 0.9069 - f1_metric: 0.4275 - auc_17: 0.4893 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6918 - acc: 0.3152 - precision: 0.2892 - recall: 0.9164 - f1_metric: 0.4324 - auc_17: 0.4918 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.3055 - precision: 0.2948 - recall: 0.9742 - f1_metric: 0.4453 - auc_17: 0.5070 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 0.3930 - precision: 0.2852 - recall: 0.7531 - f1_metric: 0.3796 - auc_17: 0.4927 - val_loss: 0.6977 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3067 - precision: 0.2993 - recall: 0.9847 - f1_metric: 0.4527 - auc_17: 0.4686 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_17: 0.5000\n",
            "Model 19 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7026 - acc: 0.4867 - precision: 0.2461 - recall: 0.5163 - f1_metric: 0.3090 - auc_18: 0.4880 - val_loss: 0.7005 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.5079 - precision: 0.3176 - recall: 0.5669 - f1_metric: 0.3795 - auc_18: 0.5016 - val_loss: 0.7041 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.3471 - precision: 0.2906 - recall: 0.8454 - f1_metric: 0.4251 - auc_18: 0.5002 - val_loss: 0.7012 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.3512 - precision: 0.2998 - recall: 0.8653 - f1_metric: 0.4414 - auc_18: 0.5161 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6856 - acc: 0.5190 - precision: 0.3095 - recall: 0.4948 - f1_metric: 0.3404 - auc_18: 0.5066 - val_loss: 0.7047 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.3679 - precision: 0.2979 - recall: 0.8518 - f1_metric: 0.4210 - auc_18: 0.5135 - val_loss: 0.7039 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.3321 - precision: 0.3043 - recall: 0.9164 - f1_metric: 0.4511 - auc_18: 0.5075 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7009 - acc: 0.3430 - precision: 0.3030 - recall: 0.8863 - f1_metric: 0.4454 - auc_18: 0.4736 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6984 - acc: 0.3728 - precision: 0.3058 - recall: 0.8397 - f1_metric: 0.4419 - auc_18: 0.5082 - val_loss: 0.7006 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.4665 - precision: 0.3086 - recall: 0.6216 - f1_metric: 0.3863 - auc_18: 0.5159 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6882 - acc: 0.3628 - precision: 0.2931 - recall: 0.8584 - f1_metric: 0.4298 - auc_18: 0.4992 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.3427 - precision: 0.3000 - recall: 0.9169 - f1_metric: 0.4450 - auc_18: 0.5079 - val_loss: 0.7007 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7014 - acc: 0.3498 - precision: 0.3072 - recall: 0.8915 - f1_metric: 0.4508 - auc_18: 0.5014 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6985 - acc: 0.3278 - precision: 0.3053 - recall: 0.9538 - f1_metric: 0.4573 - auc_18: 0.5018 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7034 - acc: 0.3961 - precision: 0.3236 - recall: 0.8512 - f1_metric: 0.4592 - auc_18: 0.5247 - val_loss: 0.6980 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.3851 - precision: 0.2825 - recall: 0.7535 - f1_metric: 0.4020 - auc_18: 0.4776 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3692 - precision: 0.3002 - recall: 0.8491 - f1_metric: 0.4376 - auc_18: 0.5224 - val_loss: 0.7018 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6946 - acc: 0.3674 - precision: 0.2983 - recall: 0.8339 - f1_metric: 0.4342 - auc_18: 0.5140 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6951 - acc: 0.3738 - precision: 0.3024 - recall: 0.8333 - f1_metric: 0.4371 - auc_18: 0.5211 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 0.4048 - precision: 0.3234 - recall: 0.8444 - f1_metric: 0.4563 - auc_18: 0.5146 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.3462 - precision: 0.2941 - recall: 0.8587 - f1_metric: 0.4282 - auc_18: 0.5086 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.3736 - precision: 0.2970 - recall: 0.8253 - f1_metric: 0.4227 - auc_18: 0.5105 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.3477 - precision: 0.3067 - recall: 0.9313 - f1_metric: 0.4542 - auc_18: 0.5063 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.3115 - precision: 0.3024 - recall: 0.9489 - f1_metric: 0.4525 - auc_18: 0.4898 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6971 - acc: 0.3679 - precision: 0.2966 - recall: 0.7960 - f1_metric: 0.4244 - auc_18: 0.4885 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6980 - acc: 0.3360 - precision: 0.3008 - recall: 0.9008 - f1_metric: 0.4451 - auc_18: 0.4985 - val_loss: 0.6938 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7116 - acc: 0.3407 - precision: 0.3204 - recall: 0.9303 - f1_metric: 0.4701 - auc_18: 0.4898 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.4957 - precision: 0.2949 - recall: 0.4791 - f1_metric: 0.3092 - auc_18: 0.5010 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7012 - acc: 0.3653 - precision: 0.3048 - recall: 0.8352 - f1_metric: 0.4401 - auc_18: 0.4855 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7027 - acc: 0.3803 - precision: 0.3200 - recall: 0.8921 - f1_metric: 0.4650 - auc_18: 0.5053 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_18: 0.5000\n",
            "Model 20 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6901 - acc: 0.5794 - precision: 0.2800 - recall: 0.3337 - f1_metric: 0.2388 - auc_19: 0.4982 - val_loss: 0.7059 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6995 - acc: 0.3740 - precision: 0.3105 - recall: 0.8840 - f1_metric: 0.4422 - auc_19: 0.5078 - val_loss: 0.6860 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_19: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7056 - acc: 0.5258 - precision: 0.2753 - recall: 0.4389 - f1_metric: 0.2992 - auc_19: 0.5012 - val_loss: 0.6843 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_19: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.6361 - precision: 0.2210 - recall: 0.1383 - f1_metric: 0.1442 - auc_19: 0.4768 - val_loss: 0.7023 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.3106 - precision: 0.3019 - recall: 0.9822 - f1_metric: 0.4550 - auc_19: 0.5132 - val_loss: 0.6888 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_19: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.6118 - precision: 0.2268 - recall: 0.2268 - f1_metric: 0.1809 - auc_19: 0.4867 - val_loss: 0.6999 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.4086 - precision: 0.2831 - recall: 0.7330 - f1_metric: 0.3733 - auc_19: 0.4853 - val_loss: 0.7085 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3291 - precision: 0.3042 - recall: 0.9263 - f1_metric: 0.4490 - auc_19: 0.5003 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.5388 - precision: 0.3078 - recall: 0.3572 - f1_metric: 0.2684 - auc_19: 0.4937 - val_loss: 0.6913 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_19: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.4988 - precision: 0.2778 - recall: 0.4519 - f1_metric: 0.3077 - auc_19: 0.4676 - val_loss: 0.6992 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7001 - acc: 0.3213 - precision: 0.3034 - recall: 0.9505 - f1_metric: 0.4514 - auc_19: 0.4690 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.3430 - precision: 0.2992 - recall: 0.9017 - f1_metric: 0.4404 - auc_19: 0.5050 - val_loss: 0.6785 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_19: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7044 - acc: 0.5159 - precision: 0.3861 - recall: 0.5273 - f1_metric: 0.3407 - auc_19: 0.5195 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.3158 - precision: 0.2919 - recall: 0.9218 - f1_metric: 0.4380 - auc_19: 0.4973 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7055 - acc: 0.3133 - precision: 0.3127 - recall: 0.9970 - f1_metric: 0.4686 - auc_19: 0.5002 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.3083 - precision: 0.3077 - recall: 0.9976 - f1_metric: 0.4647 - auc_19: 0.4989 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 0.3024 - precision: 0.3032 - recall: 0.9912 - f1_metric: 0.4591 - auc_19: 0.4953 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6890 - acc: 0.2905 - precision: 0.2889 - recall: 0.9987 - f1_metric: 0.4406 - auc_19: 0.4989 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.2928 - precision: 0.2929 - recall: 0.9996 - f1_metric: 0.4469 - auc_19: 0.5070 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6989 - acc: 0.3024 - precision: 0.3024 - recall: 0.9966 - f1_metric: 0.4597 - auc_19: 0.4924 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7030 - acc: 0.3100 - precision: 0.3096 - recall: 1.0000 - f1_metric: 0.4663 - auc_19: 0.4923 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.3002 - precision: 0.3001 - recall: 1.0000 - f1_metric: 0.4541 - auc_19: 0.5007 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6871 - acc: 0.2867 - precision: 0.2855 - recall: 0.9976 - f1_metric: 0.4381 - auc_19: 0.4892 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7056 - acc: 0.3134 - precision: 0.3134 - recall: 1.0000 - f1_metric: 0.4722 - auc_19: 0.5062 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.3167 - precision: 0.2903 - recall: 0.9225 - f1_metric: 0.4317 - auc_19: 0.4953 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3000 - precision: 0.2996 - recall: 1.0000 - f1_metric: 0.4568 - auc_19: 0.5050 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.3043 - precision: 0.3043 - recall: 1.0000 - f1_metric: 0.4621 - auc_19: 0.4983 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6983 - acc: 0.3024 - precision: 0.3024 - recall: 1.0000 - f1_metric: 0.4598 - auc_19: 0.4960 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.3043 - precision: 0.3043 - recall: 1.0000 - f1_metric: 0.4627 - auc_19: 0.5009 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6981 - acc: 0.3025 - precision: 0.3019 - recall: 0.9981 - f1_metric: 0.4579 - auc_19: 0.4975 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_19: 0.5000\n",
            "Model 21 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 9ms/step - loss: 0.7027 - acc: 0.5094 - precision: 0.2955 - recall: 0.5226 - f1_metric: 0.3222 - auc_20: 0.4882 - val_loss: 0.7155 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.3949 - precision: 0.2964 - recall: 0.7692 - f1_metric: 0.4138 - auc_20: 0.5016 - val_loss: 0.7139 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.4175 - precision: 0.2955 - recall: 0.6985 - f1_metric: 0.3781 - auc_20: 0.4866 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.4070 - precision: 0.3055 - recall: 0.7879 - f1_metric: 0.4327 - auc_20: 0.4881 - val_loss: 0.6810 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.4854 - precision: 0.2833 - recall: 0.4857 - f1_metric: 0.2714 - auc_20: 0.4805 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6984 - acc: 0.4333 - precision: 0.3078 - recall: 0.6840 - f1_metric: 0.4121 - auc_20: 0.4874 - val_loss: 0.6930 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 0.4267 - precision: 0.3085 - recall: 0.6842 - f1_metric: 0.4069 - auc_20: 0.4931 - val_loss: 0.7095 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.3936 - precision: 0.3139 - recall: 0.8087 - f1_metric: 0.4379 - auc_20: 0.5070 - val_loss: 0.6904 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.6095 - precision: 0.2983 - recall: 0.2264 - f1_metric: 0.2335 - auc_20: 0.4911 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.4103 - precision: 0.3025 - recall: 0.7311 - f1_metric: 0.4174 - auc_20: 0.4902 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.4405 - precision: 0.2856 - recall: 0.6014 - f1_metric: 0.3748 - auc_20: 0.4920 - val_loss: 0.6895 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.5841 - precision: 0.3016 - recall: 0.2897 - f1_metric: 0.2584 - auc_20: 0.4979 - val_loss: 0.7112 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.3561 - precision: 0.3012 - recall: 0.8424 - f1_metric: 0.4357 - auc_20: 0.5113 - val_loss: 0.6893 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 0.5611 - precision: 0.3098 - recall: 0.3952 - f1_metric: 0.3117 - auc_20: 0.5049 - val_loss: 0.7136 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7041 - acc: 0.3538 - precision: 0.3010 - recall: 0.8286 - f1_metric: 0.4344 - auc_20: 0.4756 - val_loss: 0.6926 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7025 - acc: 0.5377 - precision: 0.3536 - recall: 0.4946 - f1_metric: 0.3691 - auc_20: 0.5243 - val_loss: 0.6913 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6915 - acc: 0.6757 - precision: 0.2515 - recall: 0.0813 - f1_metric: 0.1137 - auc_20: 0.4874 - val_loss: 0.6920 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_20: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6903 - acc: 0.5612 - precision: 0.2623 - recall: 0.3421 - f1_metric: 0.2394 - auc_20: 0.4987 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 0.4623 - precision: 0.2985 - recall: 0.5731 - f1_metric: 0.3849 - auc_20: 0.4903 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7116 - acc: 0.3483 - precision: 0.3178 - recall: 0.8975 - f1_metric: 0.4606 - auc_20: 0.4864 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.4653 - precision: 0.2689 - recall: 0.4581 - f1_metric: 0.2712 - auc_20: 0.4752 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3577 - precision: 0.2986 - recall: 0.8564 - f1_metric: 0.4339 - auc_20: 0.4988 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.3838 - precision: 0.3087 - recall: 0.8458 - f1_metric: 0.4453 - auc_20: 0.5108 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.3432 - precision: 0.2938 - recall: 0.8975 - f1_metric: 0.4359 - auc_20: 0.4971 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.3989 - precision: 0.3055 - recall: 0.7926 - f1_metric: 0.4351 - auc_20: 0.5019 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 0.3693 - precision: 0.2992 - recall: 0.8497 - f1_metric: 0.4360 - auc_20: 0.5168 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.3243 - precision: 0.2954 - recall: 0.9103 - f1_metric: 0.4408 - auc_20: 0.4894 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3176 - precision: 0.2975 - recall: 0.9668 - f1_metric: 0.4463 - auc_20: 0.5014 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.3054 - precision: 0.2950 - recall: 0.9702 - f1_metric: 0.4461 - auc_20: 0.4930 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6947 - acc: 0.3129 - precision: 0.2992 - recall: 0.9795 - f1_metric: 0.4527 - auc_20: 0.5089 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_20: 0.5000\n",
            "Model 22 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 9ms/step - loss: 0.7046 - acc: 0.4182 - precision: 0.3193 - recall: 0.7314 - f1_metric: 0.4219 - auc_21: 0.4849 - val_loss: 0.6933 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7029 - acc: 0.3834 - precision: 0.3083 - recall: 0.7842 - f1_metric: 0.4247 - auc_21: 0.4916 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.4880 - precision: 0.3116 - recall: 0.5778 - f1_metric: 0.3769 - auc_21: 0.5156 - val_loss: 0.6814 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_21: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6995 - acc: 0.5998 - precision: 0.2794 - recall: 0.2406 - f1_metric: 0.1972 - auc_21: 0.4975 - val_loss: 0.6920 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_21: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.6172 - precision: 0.2761 - recall: 0.2300 - f1_metric: 0.2112 - auc_21: 0.5037 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.4033 - precision: 0.2990 - recall: 0.7430 - f1_metric: 0.4096 - auc_21: 0.5117 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.3612 - precision: 0.2982 - recall: 0.8382 - f1_metric: 0.4270 - auc_21: 0.4835 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6884 - acc: 0.3864 - precision: 0.2830 - recall: 0.7248 - f1_metric: 0.3933 - auc_21: 0.4891 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.3234 - precision: 0.2996 - recall: 0.9155 - f1_metric: 0.4437 - auc_21: 0.4786 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.3474 - precision: 0.2874 - recall: 0.8405 - f1_metric: 0.4197 - auc_21: 0.4793 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7013 - acc: 0.3067 - precision: 0.3059 - recall: 0.9919 - f1_metric: 0.4610 - auc_21: 0.5026 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6976 - acc: 0.3054 - precision: 0.2971 - recall: 0.9595 - f1_metric: 0.4478 - auc_21: 0.4614 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6933 - acc: 0.3122 - precision: 0.2975 - recall: 0.9791 - f1_metric: 0.4513 - auc_21: 0.4963 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.3638 - precision: 0.2796 - recall: 0.7841 - f1_metric: 0.3915 - auc_21: 0.4937 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.2973 - precision: 0.2926 - recall: 0.9717 - f1_metric: 0.4453 - auc_21: 0.4653 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.3154 - precision: 0.3056 - recall: 0.9874 - f1_metric: 0.4625 - auc_21: 0.4871 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6986 - acc: 0.3153 - precision: 0.3025 - recall: 0.9666 - f1_metric: 0.4554 - auc_21: 0.4844 - val_loss: 0.6927 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_21: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.4464 - precision: 0.2981 - recall: 0.6512 - f1_metric: 0.3930 - auc_21: 0.5060 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3592 - precision: 0.3036 - recall: 0.8798 - f1_metric: 0.4389 - auc_21: 0.5049 - val_loss: 0.6946 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3518 - precision: 0.3048 - recall: 0.8629 - f1_metric: 0.4425 - auc_21: 0.4933 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.3620 - precision: 0.2992 - recall: 0.8554 - f1_metric: 0.4337 - auc_21: 0.5176 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7012 - acc: 0.3508 - precision: 0.3138 - recall: 0.9178 - f1_metric: 0.4551 - auc_21: 0.4921 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6999 - acc: 0.3359 - precision: 0.3102 - recall: 0.9513 - f1_metric: 0.4606 - auc_21: 0.4797 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3051 - precision: 0.3044 - recall: 1.0000 - f1_metric: 0.4627 - auc_21: 0.4913 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6919 - acc: 0.2927 - precision: 0.2918 - recall: 0.9938 - f1_metric: 0.4430 - auc_21: 0.5000 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6891 - acc: 0.2924 - precision: 0.2882 - recall: 0.9875 - f1_metric: 0.4403 - auc_21: 0.4827 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7043 - acc: 0.3114 - precision: 0.3113 - recall: 0.9992 - f1_metric: 0.4686 - auc_21: 0.5035 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6918 - acc: 0.3254 - precision: 0.2935 - recall: 0.9322 - f1_metric: 0.4411 - auc_21: 0.5145 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6984 - acc: 0.3161 - precision: 0.3023 - recall: 0.9618 - f1_metric: 0.4548 - auc_21: 0.4932 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.2990 - precision: 0.2979 - recall: 0.9988 - f1_metric: 0.4526 - auc_21: 0.5048 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_21: 0.5000\n",
            "Model 23 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6965 - acc: 0.4836 - precision: 0.3054 - recall: 0.5368 - f1_metric: 0.3577 - auc_22: 0.4820 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.4076 - precision: 0.3026 - recall: 0.7388 - f1_metric: 0.4083 - auc_22: 0.4936 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.4072 - precision: 0.2851 - recall: 0.7026 - f1_metric: 0.3965 - auc_22: 0.4894 - val_loss: 0.7082 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6876 - acc: 0.4941 - precision: 0.2106 - recall: 0.4748 - f1_metric: 0.2644 - auc_22: 0.4988 - val_loss: 0.7136 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.3267 - precision: 0.3027 - recall: 0.9340 - f1_metric: 0.4492 - auc_22: 0.4923 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.4684 - precision: 0.2815 - recall: 0.5477 - f1_metric: 0.3366 - auc_22: 0.4882 - val_loss: 0.7040 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7040 - acc: 0.3299 - precision: 0.3142 - recall: 0.9763 - f1_metric: 0.4673 - auc_22: 0.5003 - val_loss: 0.6901 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_22: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.4979 - precision: 0.3078 - recall: 0.5075 - f1_metric: 0.3398 - auc_22: 0.4980 - val_loss: 0.6909 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_22: 0.5036\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.4396 - precision: 0.2771 - recall: 0.5807 - f1_metric: 0.3661 - auc_22: 0.4834 - val_loss: 0.7023 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6893 - acc: 0.3843 - precision: 0.2971 - recall: 0.7983 - f1_metric: 0.4165 - auc_22: 0.4854 - val_loss: 0.7010 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7003 - acc: 0.3365 - precision: 0.3017 - recall: 0.8876 - f1_metric: 0.4403 - auc_22: 0.4961 - val_loss: 0.6871 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_22: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.4684 - precision: 0.2888 - recall: 0.5808 - f1_metric: 0.3505 - auc_22: 0.5000 - val_loss: 0.6939 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.6348 - precision: 0.2323 - recall: 0.1772 - f1_metric: 0.1629 - auc_22: 0.4892 - val_loss: 0.7045 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6909 - acc: 0.3217 - precision: 0.2931 - recall: 0.9332 - f1_metric: 0.4388 - auc_22: 0.5201 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7017 - acc: 0.3241 - precision: 0.3034 - recall: 0.9293 - f1_metric: 0.4512 - auc_22: 0.4732 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5753 - precision: 0.3170 - recall: 0.3694 - f1_metric: 0.3055 - auc_22: 0.5044 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3487 - precision: 0.3086 - recall: 0.9117 - f1_metric: 0.4537 - auc_22: 0.5090 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3970 - precision: 0.2931 - recall: 0.7190 - f1_metric: 0.4081 - auc_22: 0.4776 - val_loss: 0.6992 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.3495 - precision: 0.2971 - recall: 0.8517 - f1_metric: 0.4346 - auc_22: 0.4877 - val_loss: 0.6980 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.3673 - precision: 0.3032 - recall: 0.8300 - f1_metric: 0.4322 - auc_22: 0.4959 - val_loss: 0.6937 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6989 - acc: 0.3784 - precision: 0.2894 - recall: 0.7187 - f1_metric: 0.4030 - auc_22: 0.4901 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.3665 - precision: 0.2996 - recall: 0.8379 - f1_metric: 0.4327 - auc_22: 0.4981 - val_loss: 0.7011 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.3128 - precision: 0.2911 - recall: 0.9459 - f1_metric: 0.4399 - auc_22: 0.4840 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.3167 - precision: 0.2982 - recall: 0.9663 - f1_metric: 0.4489 - auc_22: 0.4824 - val_loss: 0.7047 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.3635 - precision: 0.2957 - recall: 0.8322 - f1_metric: 0.4176 - auc_22: 0.4955 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.3215 - precision: 0.3008 - recall: 0.9512 - f1_metric: 0.4528 - auc_22: 0.4944 - val_loss: 0.7015 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.3530 - precision: 0.2955 - recall: 0.8529 - f1_metric: 0.4255 - auc_22: 0.4965 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.3152 - precision: 0.2994 - recall: 0.9429 - f1_metric: 0.4487 - auc_22: 0.4920 - val_loss: 0.6935 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7046 - acc: 0.3886 - precision: 0.3021 - recall: 0.7363 - f1_metric: 0.4173 - auc_22: 0.4716 - val_loss: 0.6946 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.3475 - precision: 0.2977 - recall: 0.8713 - f1_metric: 0.4382 - auc_22: 0.5041 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_22: 0.5000\n",
            "Model 24 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 11ms/step - loss: 0.6991 - acc: 0.3736 - precision: 0.2903 - recall: 0.7807 - f1_metric: 0.4029 - auc_23: 0.4772 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6845 - acc: 0.4901 - precision: 0.2730 - recall: 0.4904 - f1_metric: 0.3263 - auc_23: 0.4810 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.3371 - precision: 0.2962 - recall: 0.8827 - f1_metric: 0.4340 - auc_23: 0.4898 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.4138 - precision: 0.3146 - recall: 0.7654 - f1_metric: 0.4308 - auc_23: 0.5177 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6987 - acc: 0.5086 - precision: 0.3059 - recall: 0.5236 - f1_metric: 0.3533 - auc_23: 0.5074 - val_loss: 0.7028 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.4398 - precision: 0.3677 - recall: 0.6746 - f1_metric: 0.3678 - auc_23: 0.4925 - val_loss: 0.6943 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.4331 - precision: 0.2848 - recall: 0.6046 - f1_metric: 0.3737 - auc_23: 0.4744 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.3103 - precision: 0.2990 - recall: 0.9610 - f1_metric: 0.4501 - auc_23: 0.4974 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.3099 - precision: 0.2959 - recall: 0.9555 - f1_metric: 0.4453 - auc_23: 0.4932 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.3402 - precision: 0.2917 - recall: 0.8663 - f1_metric: 0.4249 - auc_23: 0.4958 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.4750 - precision: 0.3032 - recall: 0.5790 - f1_metric: 0.3637 - auc_23: 0.5217 - val_loss: 0.7004 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.3129 - precision: 0.2940 - recall: 0.9542 - f1_metric: 0.4449 - auc_23: 0.5017 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.3030 - precision: 0.2956 - recall: 0.9788 - f1_metric: 0.4486 - auc_23: 0.4987 - val_loss: 0.6987 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.3080 - precision: 0.2988 - recall: 0.9784 - f1_metric: 0.4529 - auc_23: 0.4830 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.3033 - precision: 0.2980 - recall: 0.9804 - f1_metric: 0.4531 - auc_23: 0.4952 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6859 - acc: 0.2833 - precision: 0.2796 - recall: 0.9669 - f1_metric: 0.4295 - auc_23: 0.4810 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6946 - acc: 0.2985 - precision: 0.2969 - recall: 0.9968 - f1_metric: 0.4506 - auc_23: 0.5040 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.3013 - precision: 0.3003 - recall: 0.9968 - f1_metric: 0.4567 - auc_23: 0.4926 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6945 - acc: 0.3017 - precision: 0.2975 - recall: 0.9932 - f1_metric: 0.4518 - auc_23: 0.4992 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.2991 - precision: 0.2981 - recall: 0.9981 - f1_metric: 0.4554 - auc_23: 0.5016 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.2985 - precision: 0.2842 - recall: 0.9601 - f1_metric: 0.4327 - auc_23: 0.4838 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7002 - acc: 0.3214 - precision: 0.3068 - recall: 0.9698 - f1_metric: 0.4611 - auc_23: 0.4973 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6988 - acc: 0.3096 - precision: 0.3024 - recall: 0.9811 - f1_metric: 0.4581 - auc_23: 0.4757 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6851 - acc: 0.2887 - precision: 0.2830 - recall: 0.9873 - f1_metric: 0.4329 - auc_23: 0.4867 - val_loss: 0.6961 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6863 - acc: 0.2960 - precision: 0.2857 - recall: 0.9823 - f1_metric: 0.4369 - auc_23: 0.4912 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6977 - acc: 0.3024 - precision: 0.3012 - recall: 0.9970 - f1_metric: 0.4574 - auc_23: 0.4937 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.2977 - precision: 0.2974 - recall: 0.9998 - f1_metric: 0.4541 - auc_23: 0.4998 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6934 - acc: 0.2970 - precision: 0.2945 - recall: 0.9863 - f1_metric: 0.4466 - auc_23: 0.4991 - val_loss: 0.6972 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7015 - acc: 0.3118 - precision: 0.3075 - recall: 0.9905 - f1_metric: 0.4635 - auc_23: 0.5010 - val_loss: 0.6978 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.3637 - precision: 0.3140 - recall: 0.8917 - f1_metric: 0.4576 - auc_23: 0.5032 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_23: 0.5000\n",
            "Model 25 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7027 - acc: 0.4288 - precision: 0.2760 - recall: 0.6369 - f1_metric: 0.3458 - auc_24: 0.4813 - val_loss: 0.6984 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.5333 - precision: 0.2252 - recall: 0.3950 - f1_metric: 0.2579 - auc_24: 0.5011 - val_loss: 0.6991 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6875 - acc: 0.4533 - precision: 0.2823 - recall: 0.6261 - f1_metric: 0.3524 - auc_24: 0.4939 - val_loss: 0.7032 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3722 - precision: 0.2914 - recall: 0.7935 - f1_metric: 0.4176 - auc_24: 0.4887 - val_loss: 0.7044 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7018 - acc: 0.3527 - precision: 0.3094 - recall: 0.8864 - f1_metric: 0.4521 - auc_24: 0.4933 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.4258 - precision: 0.3042 - recall: 0.6838 - f1_metric: 0.4079 - auc_24: 0.5025 - val_loss: 0.6859 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7022 - acc: 0.4691 - precision: 0.2991 - recall: 0.5525 - f1_metric: 0.3450 - auc_24: 0.4904 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6884 - acc: 0.5749 - precision: 0.2864 - recall: 0.2889 - f1_metric: 0.2246 - auc_24: 0.4925 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.4934 - precision: 0.2852 - recall: 0.5181 - f1_metric: 0.3375 - auc_24: 0.5064 - val_loss: 0.6988 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.4240 - precision: 0.3039 - recall: 0.7288 - f1_metric: 0.4184 - auc_24: 0.5199 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6986 - acc: 0.3394 - precision: 0.2985 - recall: 0.8724 - f1_metric: 0.4326 - auc_24: 0.4907 - val_loss: 0.6813 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6986 - acc: 0.5949 - precision: 0.3098 - recall: 0.2727 - f1_metric: 0.2353 - auc_24: 0.5107 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7017 - acc: 0.3346 - precision: 0.2997 - recall: 0.8890 - f1_metric: 0.4402 - auc_24: 0.4751 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6861 - acc: 0.6517 - precision: 0.2805 - recall: 0.1542 - f1_metric: 0.1851 - auc_24: 0.4996 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6893 - acc: 0.4427 - precision: 0.2974 - recall: 0.6873 - f1_metric: 0.4028 - auc_24: 0.5114 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.4138 - precision: 0.2977 - recall: 0.7220 - f1_metric: 0.3968 - auc_24: 0.4992 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.3725 - precision: 0.2968 - recall: 0.8050 - f1_metric: 0.4265 - auc_24: 0.4931 - val_loss: 0.6947 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.3149 - precision: 0.2957 - recall: 0.9065 - f1_metric: 0.4403 - auc_24: 0.5019 - val_loss: 0.6958 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7052 - acc: 0.3271 - precision: 0.3100 - recall: 0.9417 - f1_metric: 0.4604 - auc_24: 0.4780 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5944 - precision: 0.2919 - recall: 0.2845 - f1_metric: 0.2438 - auc_24: 0.4889 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6939 - acc: 0.3515 - precision: 0.3014 - recall: 0.8936 - f1_metric: 0.4408 - auc_24: 0.4975 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.3130 - precision: 0.3069 - recall: 0.9884 - f1_metric: 0.4631 - auc_24: 0.4892 - val_loss: 0.6923 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6977 - acc: 0.4937 - precision: 0.3183 - recall: 0.5527 - f1_metric: 0.3719 - auc_24: 0.5128 - val_loss: 0.6930 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_24: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.5281 - precision: 0.2955 - recall: 0.4132 - f1_metric: 0.3278 - auc_24: 0.4793 - val_loss: 0.6935 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.4555 - precision: 0.2873 - recall: 0.5559 - f1_metric: 0.3582 - auc_24: 0.4981 - val_loss: 0.6953 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.3122 - precision: 0.3015 - recall: 0.9905 - f1_metric: 0.4554 - auc_24: 0.5050 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7009 - acc: 0.3093 - precision: 0.3067 - recall: 0.9965 - f1_metric: 0.4639 - auc_24: 0.4902 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3017 - precision: 0.2938 - recall: 0.9777 - f1_metric: 0.4468 - auc_24: 0.5041 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6948 - acc: 0.2986 - precision: 0.2975 - recall: 0.9998 - f1_metric: 0.4529 - auc_24: 0.5027 - val_loss: 0.6966 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.3001 - precision: 0.2992 - recall: 0.9965 - f1_metric: 0.4531 - auc_24: 0.4986 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_24: 0.5000\n",
            "Model 26 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6939 - acc: 0.5252 - precision: 0.2596 - recall: 0.3964 - f1_metric: 0.2537 - auc_25: 0.4731 - val_loss: 0.7187 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6863 - acc: 0.5190 - precision: 0.1979 - recall: 0.4864 - f1_metric: 0.2591 - auc_25: 0.4999 - val_loss: 0.7143 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.3922 - precision: 0.2723 - recall: 0.7166 - f1_metric: 0.3701 - auc_25: 0.5041 - val_loss: 0.7096 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7067 - acc: 0.3459 - precision: 0.3102 - recall: 0.8984 - f1_metric: 0.4497 - auc_25: 0.4673 - val_loss: 0.6931 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.4719 - precision: 0.2930 - recall: 0.5408 - f1_metric: 0.3488 - auc_25: 0.4752 - val_loss: 0.7004 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.4086 - precision: 0.2583 - recall: 0.7527 - f1_metric: 0.3651 - auc_25: 0.4974 - val_loss: 0.7005 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6911 - acc: 0.3263 - precision: 0.2899 - recall: 0.9018 - f1_metric: 0.4305 - auc_25: 0.4747 - val_loss: 0.7008 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7016 - acc: 0.3121 - precision: 0.3069 - recall: 0.9846 - f1_metric: 0.4615 - auc_25: 0.5055 - val_loss: 0.6945 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.3999 - precision: 0.2948 - recall: 0.6991 - f1_metric: 0.3931 - auc_25: 0.4957 - val_loss: 0.6921 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7065 - acc: 0.3862 - precision: 0.3269 - recall: 0.8402 - f1_metric: 0.4468 - auc_25: 0.4938 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7040 - acc: 0.4017 - precision: 0.2843 - recall: 0.6385 - f1_metric: 0.3577 - auc_25: 0.4649 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6917 - acc: 0.6077 - precision: 0.3030 - recall: 0.2453 - f1_metric: 0.2300 - auc_25: 0.4790 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.4171 - precision: 0.2918 - recall: 0.7096 - f1_metric: 0.3678 - auc_25: 0.5085 - val_loss: 0.7043 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6876 - acc: 0.3831 - precision: 0.2706 - recall: 0.7114 - f1_metric: 0.3473 - auc_25: 0.4716 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.2994 - precision: 0.2924 - recall: 0.9789 - f1_metric: 0.4431 - auc_25: 0.4947 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.2974 - precision: 0.2973 - recall: 0.9997 - f1_metric: 0.4517 - auc_25: 0.4888 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.4548 - precision: 0.3208 - recall: 0.6579 - f1_metric: 0.3985 - auc_25: 0.4965 - val_loss: 0.6818 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5317 - precision: 0.3059 - recall: 0.4347 - f1_metric: 0.3407 - auc_25: 0.4874 - val_loss: 0.7013 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6974 - acc: 0.3024 - precision: 0.3006 - recall: 0.9959 - f1_metric: 0.4559 - auc_25: 0.4824 - val_loss: 0.6935 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.4868 - precision: 0.3164 - recall: 0.5288 - f1_metric: 0.3768 - auc_25: 0.5067 - val_loss: 0.6910 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 0.4796 - precision: 0.3184 - recall: 0.5962 - f1_metric: 0.3859 - auc_25: 0.5011 - val_loss: 0.6926 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6909 - acc: 0.5458 - precision: 0.3204 - recall: 0.4814 - f1_metric: 0.3662 - auc_25: 0.5080 - val_loss: 0.6988 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.3589 - precision: 0.3061 - recall: 0.8835 - f1_metric: 0.4412 - auc_25: 0.5159 - val_loss: 0.6906 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6950 - acc: 0.4507 - precision: 0.2855 - recall: 0.5605 - f1_metric: 0.3466 - auc_25: 0.4657 - val_loss: 0.6866 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.5235 - precision: 0.3114 - recall: 0.4831 - f1_metric: 0.3554 - auc_25: 0.5142 - val_loss: 0.7044 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6880 - acc: 0.5228 - precision: 0.3109 - recall: 0.4807 - f1_metric: 0.3262 - auc_25: 0.4971 - val_loss: 0.7246 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6990 - acc: 0.3071 - precision: 0.3035 - recall: 0.9936 - f1_metric: 0.4572 - auc_25: 0.5135 - val_loss: 0.6883 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_25: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7035 - acc: 0.4073 - precision: 0.3006 - recall: 0.6966 - f1_metric: 0.3979 - auc_25: 0.4899 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.4590 - precision: 0.2842 - recall: 0.5493 - f1_metric: 0.3473 - auc_25: 0.4850 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6925 - acc: 0.3945 - precision: 0.2990 - recall: 0.7518 - f1_metric: 0.3996 - auc_25: 0.4898 - val_loss: 0.7044 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_25: 0.5000\n",
            "Model 27 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 9ms/step - loss: 0.6998 - acc: 0.4751 - precision: 0.2894 - recall: 0.5246 - f1_metric: 0.2982 - auc_26: 0.4743 - val_loss: 0.7026 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.3731 - precision: 0.2966 - recall: 0.7949 - f1_metric: 0.4187 - auc_26: 0.4991 - val_loss: 0.7030 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.3773 - precision: 0.2935 - recall: 0.7857 - f1_metric: 0.3946 - auc_26: 0.5046 - val_loss: 0.7028 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6959 - acc: 0.3328 - precision: 0.3019 - recall: 0.9365 - f1_metric: 0.4497 - auc_26: 0.5102 - val_loss: 0.6856 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_26: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6951 - acc: 0.4952 - precision: 0.2754 - recall: 0.4515 - f1_metric: 0.3085 - auc_26: 0.4761 - val_loss: 0.6993 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6953 - acc: 0.4551 - precision: 0.3297 - recall: 0.6846 - f1_metric: 0.4020 - auc_26: 0.5056 - val_loss: 0.6956 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.4977\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7057 - acc: 0.4878 - precision: 0.3234 - recall: 0.5700 - f1_metric: 0.3951 - auc_26: 0.5215 - val_loss: 0.6941 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6951 - acc: 0.4403 - precision: 0.3014 - recall: 0.6821 - f1_metric: 0.4051 - auc_26: 0.4849 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_26: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.3969 - precision: 0.2846 - recall: 0.7052 - f1_metric: 0.3888 - auc_26: 0.4744 - val_loss: 0.6951 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6953 - acc: 0.3691 - precision: 0.3074 - recall: 0.8748 - f1_metric: 0.4484 - auc_26: 0.4905 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6931 - acc: 0.3219 - precision: 0.2967 - recall: 0.9509 - f1_metric: 0.4452 - auc_26: 0.5005 - val_loss: 0.6908 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_26: 0.5023\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.3426 - precision: 0.2801 - recall: 0.8022 - f1_metric: 0.4039 - auc_26: 0.4782 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.3018 - precision: 0.2934 - recall: 0.9413 - f1_metric: 0.4426 - auc_26: 0.4961 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.3140 - precision: 0.2933 - recall: 0.9371 - f1_metric: 0.4403 - auc_26: 0.4990 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6920 - acc: 0.3557 - precision: 0.2948 - recall: 0.8702 - f1_metric: 0.4206 - auc_26: 0.5099 - val_loss: 0.6905 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_26: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7021 - acc: 0.3452 - precision: 0.2980 - recall: 0.8719 - f1_metric: 0.4371 - auc_26: 0.4777 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.3599 - precision: 0.2971 - recall: 0.8223 - f1_metric: 0.4257 - auc_26: 0.4864 - val_loss: 0.6983 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6964 - acc: 0.3229 - precision: 0.2983 - recall: 0.9367 - f1_metric: 0.4461 - auc_26: 0.5096 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6996 - acc: 0.3116 - precision: 0.3014 - recall: 0.9581 - f1_metric: 0.4529 - auc_26: 0.4891 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6983 - acc: 0.4100 - precision: 0.3063 - recall: 0.7432 - f1_metric: 0.4159 - auc_26: 0.5078 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6993 - acc: 0.3758 - precision: 0.3023 - recall: 0.7958 - f1_metric: 0.4088 - auc_26: 0.4718 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.4573 - precision: 0.3208 - recall: 0.7231 - f1_metric: 0.4338 - auc_26: 0.5293 - val_loss: 0.6886 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_26: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6959 - acc: 0.5960 - precision: 0.3021 - recall: 0.2490 - f1_metric: 0.2457 - auc_26: 0.5099 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.3938 - precision: 0.2959 - recall: 0.7739 - f1_metric: 0.4118 - auc_26: 0.4929 - val_loss: 0.6992 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6875 - acc: 0.5204 - precision: 0.2813 - recall: 0.4648 - f1_metric: 0.2871 - auc_26: 0.5000 - val_loss: 0.7003 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.3165 - precision: 0.3043 - recall: 0.9700 - f1_metric: 0.4562 - auc_26: 0.5056 - val_loss: 0.7016 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.4823 - precision: 0.2941 - recall: 0.5492 - f1_metric: 0.3672 - auc_26: 0.5064 - val_loss: 0.7016 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.4035 - precision: 0.3034 - recall: 0.7460 - f1_metric: 0.4253 - auc_26: 0.5139 - val_loss: 0.7011 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.3176 - precision: 0.3102 - recall: 0.9788 - f1_metric: 0.4636 - auc_26: 0.4924 - val_loss: 0.6998 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.2929 - precision: 0.2903 - recall: 0.9788 - f1_metric: 0.4417 - auc_26: 0.4959 - val_loss: 0.6989 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_26: 0.5000\n",
            "Model 28 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.7073 - acc: 0.3713 - precision: 0.3133 - recall: 0.8279 - f1_metric: 0.4426 - auc_27: 0.4660 - val_loss: 0.6700 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7037 - acc: 0.5486 - precision: 0.3117 - recall: 0.3376 - f1_metric: 0.2805 - auc_27: 0.4730 - val_loss: 0.6929 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7039 - acc: 0.3972 - precision: 0.2943 - recall: 0.7063 - f1_metric: 0.3969 - auc_27: 0.4833 - val_loss: 0.6881 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6981 - acc: 0.5081 - precision: 0.2758 - recall: 0.4461 - f1_metric: 0.3022 - auc_27: 0.4932 - val_loss: 0.6816 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7042 - acc: 0.5412 - precision: 0.3286 - recall: 0.3727 - f1_metric: 0.2952 - auc_27: 0.4963 - val_loss: 0.6733 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7020 - acc: 0.5699 - precision: 0.2585 - recall: 0.2762 - f1_metric: 0.2464 - auc_27: 0.4826 - val_loss: 0.7047 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5210 - precision: 0.3133 - recall: 0.4714 - f1_metric: 0.3167 - auc_27: 0.5021 - val_loss: 0.7015 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6934 - acc: 0.4761 - precision: 0.3156 - recall: 0.6125 - f1_metric: 0.3910 - auc_27: 0.5098 - val_loss: 0.7059 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6954 - acc: 0.3480 - precision: 0.2990 - recall: 0.8719 - f1_metric: 0.4357 - auc_27: 0.4997 - val_loss: 0.6928 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6881 - acc: 0.5268 - precision: 0.2888 - recall: 0.4567 - f1_metric: 0.3412 - auc_27: 0.4996 - val_loss: 0.7076 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.3311 - precision: 0.2961 - recall: 0.8949 - f1_metric: 0.4389 - auc_27: 0.5086 - val_loss: 0.6779 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7020 - acc: 0.5410 - precision: 0.3430 - recall: 0.4143 - f1_metric: 0.3031 - auc_27: 0.4974 - val_loss: 0.6877 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6986 - acc: 0.5020 - precision: 0.3081 - recall: 0.5085 - f1_metric: 0.3434 - auc_27: 0.4854 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.3747 - precision: 0.3067 - recall: 0.8299 - f1_metric: 0.4404 - auc_27: 0.5009 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6954 - acc: 0.3983 - precision: 0.2851 - recall: 0.6980 - f1_metric: 0.3961 - auc_27: 0.4705 - val_loss: 0.6917 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.4515 - precision: 0.2978 - recall: 0.6416 - f1_metric: 0.3907 - auc_27: 0.4987 - val_loss: 0.7076 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.3230 - precision: 0.2889 - recall: 0.8761 - f1_metric: 0.4266 - auc_27: 0.4699 - val_loss: 0.6982 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7008 - acc: 0.3260 - precision: 0.2992 - recall: 0.8988 - f1_metric: 0.4405 - auc_27: 0.4826 - val_loss: 0.6905 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6946 - acc: 0.4911 - precision: 0.3137 - recall: 0.5664 - f1_metric: 0.3814 - auc_27: 0.5149 - val_loss: 0.7001 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.4992\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7019 - acc: 0.3947 - precision: 0.3183 - recall: 0.8343 - f1_metric: 0.4477 - auc_27: 0.5036 - val_loss: 0.6895 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.6189 - precision: 0.2859 - recall: 0.1910 - f1_metric: 0.2149 - auc_27: 0.5043 - val_loss: 0.6912 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_27: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.5562 - precision: 0.3042 - recall: 0.3392 - f1_metric: 0.2915 - auc_27: 0.5045 - val_loss: 0.6944 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6892 - acc: 0.3597 - precision: 0.2914 - recall: 0.8333 - f1_metric: 0.4179 - auc_27: 0.5005 - val_loss: 0.6952 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6962 - acc: 0.3087 - precision: 0.3015 - recall: 0.9919 - f1_metric: 0.4565 - auc_27: 0.4942 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6965 - acc: 0.3351 - precision: 0.3017 - recall: 0.9198 - f1_metric: 0.4491 - auc_27: 0.5274 - val_loss: 0.6949 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6924 - acc: 0.3964 - precision: 0.2986 - recall: 0.7499 - f1_metric: 0.4137 - auc_27: 0.4954 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6941 - acc: 0.3384 - precision: 0.2950 - recall: 0.8838 - f1_metric: 0.4352 - auc_27: 0.4732 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7053 - acc: 0.3816 - precision: 0.3155 - recall: 0.8300 - f1_metric: 0.4499 - auc_27: 0.4980 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.4885 - precision: 0.2984 - recall: 0.5524 - f1_metric: 0.3521 - auc_27: 0.5075 - val_loss: 0.6991 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.3108 - precision: 0.2985 - recall: 0.9627 - f1_metric: 0.4492 - auc_27: 0.4794 - val_loss: 0.6971 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_27: 0.5000\n",
            "Model 29 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6964 - acc: 0.4900 - precision: 0.2748 - recall: 0.5145 - f1_metric: 0.3087 - auc_28: 0.5036 - val_loss: 0.7162 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6917 - acc: 0.4002 - precision: 0.2926 - recall: 0.7368 - f1_metric: 0.4000 - auc_28: 0.4866 - val_loss: 0.7021 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6944 - acc: 0.4814 - precision: 0.2835 - recall: 0.5284 - f1_metric: 0.2996 - auc_28: 0.4986 - val_loss: 0.6925 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.3703 - precision: 0.3144 - recall: 0.8693 - f1_metric: 0.4482 - auc_28: 0.4998 - val_loss: 0.6904 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6928 - acc: 0.5803 - precision: 0.3167 - recall: 0.3442 - f1_metric: 0.2729 - auc_28: 0.5101 - val_loss: 0.7004 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 0.3474 - precision: 0.2921 - recall: 0.8474 - f1_metric: 0.4207 - auc_28: 0.4934 - val_loss: 0.6940 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6888 - acc: 0.4500 - precision: 0.2930 - recall: 0.6163 - f1_metric: 0.3826 - auc_28: 0.5038 - val_loss: 0.7045 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7060 - acc: 0.3547 - precision: 0.3089 - recall: 0.8591 - f1_metric: 0.4448 - auc_28: 0.4698 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.3756 - precision: 0.3049 - recall: 0.8296 - f1_metric: 0.4396 - auc_28: 0.4958 - val_loss: 0.6850 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.6131 - precision: 0.2956 - recall: 0.2468 - f1_metric: 0.2388 - auc_28: 0.5007 - val_loss: 0.6932 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.3595 - precision: 0.3079 - recall: 0.8538 - f1_metric: 0.4397 - auc_28: 0.5183 - val_loss: 0.6914 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6964 - acc: 0.3972 - precision: 0.2963 - recall: 0.7255 - f1_metric: 0.4075 - auc_28: 0.4814 - val_loss: 0.6925 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6919 - acc: 0.5094 - precision: 0.3009 - recall: 0.5140 - f1_metric: 0.3651 - auc_28: 0.5054 - val_loss: 0.7080 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6933 - acc: 0.4534 - precision: 0.2730 - recall: 0.5802 - f1_metric: 0.3214 - auc_28: 0.4864 - val_loss: 0.6946 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6915 - acc: 0.3886 - precision: 0.2926 - recall: 0.7750 - f1_metric: 0.4080 - auc_28: 0.5136 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.3254 - precision: 0.2888 - recall: 0.8911 - f1_metric: 0.4287 - auc_28: 0.4965 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.3107 - precision: 0.2921 - recall: 0.9522 - f1_metric: 0.4425 - auc_28: 0.5121 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7020 - acc: 0.3092 - precision: 0.3080 - recall: 0.9980 - f1_metric: 0.4656 - auc_28: 0.4905 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.2938 - precision: 0.2928 - recall: 0.9922 - f1_metric: 0.4456 - auc_28: 0.5152 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7037 - acc: 0.3122 - precision: 0.3105 - recall: 0.9963 - f1_metric: 0.4666 - auc_28: 0.4943 - val_loss: 0.6968 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6966 - acc: 0.2996 - precision: 0.2991 - recall: 0.9949 - f1_metric: 0.4532 - auc_28: 0.4961 - val_loss: 0.6965 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6936 - acc: 0.2945 - precision: 0.2944 - recall: 0.9951 - f1_metric: 0.4479 - auc_28: 0.4856 - val_loss: 0.6967 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7024 - acc: 0.3122 - precision: 0.3092 - recall: 0.9954 - f1_metric: 0.4671 - auc_28: 0.5025 - val_loss: 0.6963 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6967 - acc: 0.3035 - precision: 0.2989 - recall: 0.9838 - f1_metric: 0.4540 - auc_28: 0.4833 - val_loss: 0.6973 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 0.3442 - precision: 0.3013 - recall: 0.8696 - f1_metric: 0.4418 - auc_28: 0.5026 - val_loss: 0.6960 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6981 - acc: 0.3518 - precision: 0.3066 - recall: 0.9069 - f1_metric: 0.4477 - auc_28: 0.5075 - val_loss: 0.6918 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7057 - acc: 0.3736 - precision: 0.3016 - recall: 0.7781 - f1_metric: 0.4193 - auc_28: 0.4829 - val_loss: 0.6889 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_28: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6855 - acc: 0.5839 - precision: 0.2829 - recall: 0.3690 - f1_metric: 0.2550 - auc_28: 0.5140 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7038 - acc: 0.3120 - precision: 0.3112 - recall: 0.9992 - f1_metric: 0.4704 - auc_28: 0.4991 - val_loss: 0.6985 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.7059 - acc: 0.3297 - precision: 0.3158 - recall: 0.9729 - f1_metric: 0.4705 - auc_28: 0.5094 - val_loss: 0.6981 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_28: 0.5000\n",
            "Model 30 Fitting\n",
            "Epoch 1/30\n",
            "102/102 [==============================] - 2s 8ms/step - loss: 0.6912 - acc: 0.6295 - precision: 0.2081 - recall: 0.2062 - f1_metric: 0.1471 - auc_29: 0.5160 - val_loss: 0.6911 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 2/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5079 - precision: 0.2877 - recall: 0.4553 - f1_metric: 0.3321 - auc_29: 0.4876 - val_loss: 0.7109 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 3/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7067 - acc: 0.3307 - precision: 0.3121 - recall: 0.9337 - f1_metric: 0.4579 - auc_29: 0.4821 - val_loss: 0.6789 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 4/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7018 - acc: 0.6001 - precision: 0.2556 - recall: 0.2067 - f1_metric: 0.1906 - auc_29: 0.4924 - val_loss: 0.6942 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 5/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6975 - acc: 0.4477 - precision: 0.2949 - recall: 0.6312 - f1_metric: 0.3776 - auc_29: 0.4882 - val_loss: 0.6893 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 6/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6929 - acc: 0.5894 - precision: 0.2519 - recall: 0.2464 - f1_metric: 0.1934 - auc_29: 0.4628 - val_loss: 0.6970 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 7/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.4483 - precision: 0.2845 - recall: 0.5946 - f1_metric: 0.3642 - auc_29: 0.4893 - val_loss: 0.6957 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 8/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6882 - acc: 0.4322 - precision: 0.2997 - recall: 0.6652 - f1_metric: 0.3782 - auc_29: 0.4919 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 9/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6938 - acc: 0.2963 - precision: 0.2910 - recall: 0.9639 - f1_metric: 0.4395 - auc_29: 0.4778 - val_loss: 0.7019 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 10/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6987 - acc: 0.3103 - precision: 0.3027 - recall: 0.9767 - f1_metric: 0.4580 - auc_29: 0.5215 - val_loss: 0.6934 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 11/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6921 - acc: 0.4217 - precision: 0.2854 - recall: 0.6466 - f1_metric: 0.3805 - auc_29: 0.4831 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 12/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7006 - acc: 0.3062 - precision: 0.3058 - recall: 0.9994 - f1_metric: 0.4644 - auc_29: 0.4909 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 13/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6949 - acc: 0.4271 - precision: 0.2886 - recall: 0.6682 - f1_metric: 0.3739 - auc_29: 0.4812 - val_loss: 0.6917 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 14/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.4148 - precision: 0.2989 - recall: 0.7120 - f1_metric: 0.4036 - auc_29: 0.5027 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 15/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6953 - acc: 0.4378 - precision: 0.2826 - recall: 0.5834 - f1_metric: 0.3614 - auc_29: 0.4732 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 16/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6985 - acc: 0.3134 - precision: 0.3049 - recall: 0.9894 - f1_metric: 0.4602 - auc_29: 0.4910 - val_loss: 0.6964 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 17/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.3085 - precision: 0.2997 - recall: 0.9774 - f1_metric: 0.4503 - auc_29: 0.4833 - val_loss: 0.6950 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 18/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.3446 - precision: 0.3015 - recall: 0.8769 - f1_metric: 0.4403 - auc_29: 0.4888 - val_loss: 0.6955 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.4949\n",
            "Epoch 19/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7030 - acc: 0.3152 - precision: 0.3094 - recall: 0.9819 - f1_metric: 0.4655 - auc_29: 0.5038 - val_loss: 0.6979 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 20/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6968 - acc: 0.3383 - precision: 0.2962 - recall: 0.8776 - f1_metric: 0.4359 - auc_29: 0.4949 - val_loss: 0.6948 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 21/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6913 - acc: 0.3753 - precision: 0.2918 - recall: 0.7940 - f1_metric: 0.4119 - auc_29: 0.4912 - val_loss: 0.6916 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 22/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6935 - acc: 0.4412 - precision: 0.3037 - recall: 0.6450 - f1_metric: 0.3791 - auc_29: 0.4806 - val_loss: 0.6974 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 23/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6875 - acc: 0.3484 - precision: 0.2916 - recall: 0.8413 - f1_metric: 0.4167 - auc_29: 0.5034 - val_loss: 0.6975 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 24/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6921 - acc: 0.2984 - precision: 0.2925 - recall: 0.9797 - f1_metric: 0.4441 - auc_29: 0.5041 - val_loss: 0.6995 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 25/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7014 - acc: 0.3050 - precision: 0.3050 - recall: 0.9890 - f1_metric: 0.4604 - auc_29: 0.4843 - val_loss: 0.6969 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 26/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6944 - acc: 0.3558 - precision: 0.2952 - recall: 0.7897 - f1_metric: 0.4122 - auc_29: 0.4856 - val_loss: 0.6936 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 27/30\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.3460 - precision: 0.2993 - recall: 0.8905 - f1_metric: 0.4403 - auc_29: 0.5021 - val_loss: 0.6959 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 28/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.7005 - acc: 0.4724 - precision: 0.3094 - recall: 0.5999 - f1_metric: 0.3924 - auc_29: 0.5116 - val_loss: 0.6924 - val_acc: 0.7285 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_metric: 0.0000e+00 - val_auc_29: 0.5000\n",
            "Epoch 29/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6988 - acc: 0.4474 - precision: 0.2960 - recall: 0.5805 - f1_metric: 0.3574 - auc_29: 0.4673 - val_loss: 0.6986 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n",
            "Epoch 30/30\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6939 - acc: 0.3072 - precision: 0.2969 - recall: 0.9751 - f1_metric: 0.4480 - auc_29: 0.4882 - val_loss: 0.6962 - val_acc: 0.2715 - val_precision: 0.2687 - val_recall: 1.0000 - val_f1_metric: 0.4144 - val_auc_29: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GfHp9ww0FWvB",
        "outputId": "a5965bf1-2f66-42c6-bc79-8c4754855c4f"
      },
      "source": [
        "#Run model predictions\n",
        "\n",
        "# Model 1 \n",
        "prediction_features_1 = model1.predict(features_test)\n",
        "performance1 = model1.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 2 \n",
        "prediction_features_2 = model2.predict(features_test)\n",
        "performance2 = model2.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 3 \n",
        "prediction_features_3 = model3.predict(features_test)\n",
        "performance3 = model3.evaluate(features_test, labels_test)\n",
        "print(performance1)\n",
        "# Model 4 \n",
        "prediction_features_4 = model4.predict(features_test)\n",
        "performance4 = model4.evaluate(features_test, labels_test)\n",
        "print(performance4)\n",
        "# Model 5 \n",
        "prediction_features_5 = model5.predict(features_test)\n",
        "performance5 = model5.evaluate(features_test, labels_test)\n",
        "print(performance5)\n",
        "\n",
        "# Model 6 \n",
        "prediction_features_6 = model6.predict(features_test)\n",
        "performance6 = model6.evaluate(features_test, labels_test)\n",
        "print(performance6)\n",
        "# Model 7\n",
        "prediction_features_7 = model7.predict(features_test)\n",
        "performance7 = model7.evaluate(features_test, labels_test)\n",
        "print(performance7)\n",
        "# Model 8 \n",
        "prediction_features_8 = model8.predict(features_test)\n",
        "performance8 = model8.evaluate(features_test, labels_test)\n",
        "print(performance8)\n",
        "# Model 9\n",
        "prediction_features_9 = model9.predict(features_test)\n",
        "performance9 = model9.evaluate(features_test, labels_test)\n",
        "print(performance9)\n",
        "# Model 10\n",
        "prediction_features_10 = model10.predict(features_test)\n",
        "performance10 = model10.evaluate(features_test, labels_test)\n",
        "print(performance10)\n",
        "\n",
        "# Model 11 \n",
        "prediction_features_11 = model11.predict(features_test)\n",
        "performance11 = model11.evaluate(features_test, labels_test)\n",
        "print(performance11)\n",
        "# Model 12 \n",
        "prediction_features_12 = model12.predict(features_test)\n",
        "performance12 = model12.evaluate(features_test, labels_test)\n",
        "print(performance12)\n",
        "# Model 13 \n",
        "prediction_features_13 = model13.predict(features_test)\n",
        "performance13 = model13.evaluate(features_test, labels_test)\n",
        "print(performance13)\n",
        "# Model 14 \n",
        "prediction_features_14 = model14.predict(features_test)\n",
        "performance14 = model14.evaluate(features_test, labels_test)\n",
        "print(performance14)\n",
        "# Model 15 \n",
        "prediction_features_15 = model15.predict(features_test)\n",
        "performance15 = model15.evaluate(features_test, labels_test)\n",
        "print(performance15)\n",
        "\n",
        "# Model 16\n",
        "prediction_features_16 = model16.predict(features_test)\n",
        "performance16 = model16.evaluate(features_test, labels_test)\n",
        "print(performance16)\n",
        "# Model 17\n",
        "prediction_features_17 = model17.predict(features_test)\n",
        "performance17 = model17.evaluate(features_test, labels_test)\n",
        "print(performance17)\n",
        "# Model 18 \n",
        "prediction_features_18 = model18.predict(features_test)\n",
        "performance18 = model18.evaluate(features_test, labels_test)\n",
        "print(performance18)\n",
        "# Model 19\n",
        "prediction_features_19 = model19.predict(features_test)\n",
        "performance19 = model19.evaluate(features_test, labels_test)\n",
        "print(performance19)\n",
        "# Model 20 \n",
        "prediction_features_20 = model20.predict(features_test)\n",
        "performance20 = model20.evaluate(features_test, labels_test)\n",
        "print(performance20)\n",
        "\n",
        "# Model 21\n",
        "prediction_features_21 = model21.predict(features_test)\n",
        "performance21 = model21.evaluate(features_test, labels_test)\n",
        "print(performance21)\n",
        "# Model 22\n",
        "prediction_features_22 = model22.predict(features_test)\n",
        "performance22 = model22.evaluate(features_test, labels_test)\n",
        "print(performance22)\n",
        "# Model 23\n",
        "prediction_features_23 = model23.predict(features_test)\n",
        "performance23 = model23.evaluate(features_test, labels_test)\n",
        "print(performance23)\n",
        "# Model 24 \n",
        "prediction_features_24 = model24.predict(features_test)\n",
        "performance24 = model24.evaluate(features_test, labels_test)\n",
        "print(performance24)\n",
        "# Model 25\n",
        "prediction_features_25 = model25.predict(features_test)\n",
        "performance25 = model25.evaluate(features_test, labels_test)\n",
        "print(performance25)\n",
        "\n",
        "# Model 26 \n",
        "prediction_features_26 = model26.predict(features_test)\n",
        "performance26 = model26.evaluate(features_test, labels_test)\n",
        "print(performance26)\n",
        "# Model 27 \n",
        "prediction_features_27 = model27.predict(features_test)\n",
        "performance27 = model27.evaluate(features_test, labels_test)\n",
        "print(performance27)\n",
        "# Model 28 \n",
        "prediction_features_28 = model28.predict(features_test)\n",
        "performance28 = model28.evaluate(features_test, labels_test)\n",
        "print(performance28)\n",
        "# Model 29\n",
        "prediction_features_29 = model29.predict(features_test)\n",
        "performance29 = model29.evaluate(features_test, labels_test)\n",
        "print(performance29)\n",
        "# Model 30 \n",
        "prediction_features_30 = model30.predict(features_test)\n",
        "performance30 = model30.evaluate(features_test, labels_test)\n",
        "print(performance30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6959 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc: 0.5000\n",
            "[0.6958709955215454, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6961 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_1: 0.5000\n",
            "[0.6958709955215454, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6968 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_2: 0.5000\n",
            "[0.6958709955215454, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6969 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_3: 0.5000\n",
            "[0.696880578994751, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6952 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_4: 0.5000\n",
            "[0.6951702833175659, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6948 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_5: 0.5000\n",
            "[0.6948315501213074, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6969 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_6: 0.5000\n",
            "[0.6968532204627991, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6953 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_7: 0.5000\n",
            "[0.6953134536743164, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6962 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_8: 0.5000\n",
            "[0.6962294578552246, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6949 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_9: 0.5000\n",
            "[0.6949440836906433, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6961 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_10: 0.5000\n",
            "[0.6960680484771729, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6979 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_11: 0.5000\n",
            "[0.6978933811187744, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6966 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_12: 0.5000\n",
            "[0.6965769529342651, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6966 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_13: 0.5000\n",
            "[0.6965563893318176, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6965 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_14: 0.5000\n",
            "[0.6965247392654419, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6943 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_15: 0.5000\n",
            "[0.6943197846412659, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6970 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_16: 0.5000\n",
            "[0.696986973285675, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_17: 0.5000\n",
            "[0.6976553201675415, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6958 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_18: 0.5000\n",
            "[0.6958005428314209, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6961 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_19: 0.5000\n",
            "[0.696056604385376, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6968 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_20: 0.5000\n",
            "[0.6967806816101074, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6963 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_21: 0.5000\n",
            "[0.6962546110153198, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6953 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_22: 0.5000\n",
            "[0.6952747106552124, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6977 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_23: 0.5000\n",
            "[0.6977326273918152, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6958 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_24: 0.5000\n",
            "[0.6957834959030151, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7029 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_25: 0.5000\n",
            "[0.7029138803482056, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6981 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_26: 0.5000\n",
            "[0.6980879902839661, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6966 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_27: 0.5000\n",
            "[0.6966022253036499, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6974 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_28: 0.5000\n",
            "[0.6974197030067444, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6958 - acc: 0.3026 - precision: 0.3030 - recall: 1.0000 - f1_metric: 0.4591 - auc_29: 0.5000\n",
            "[0.6957898139953613, 0.30255404114723206, 0.30303484201431274, 1.0, 0.45905670523643494, 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-kn2xq4Ts7s-",
        "outputId": "7e8a6f6e-dcd9-4a4d-c1d4-8c972c604813"
      },
      "source": [
        "# Averages\n",
        "\n",
        "# Loss\n",
        "loss_avg = (performance1[0] + performance2[0] + performance3[0] + performance4[0] + performance5[0] + performance6[0] + performance7[0] + performance8[0] + performance9[0] + performance10[0]\n",
        "            + performance11[0] + performance12[0] + performance13[0] + performance14[0] + performance15[0] + performance16[0] + performance17[0] + performance18[0] + performance19[0] + performance20[0]\n",
        "            + performance21[0] + performance22[0] + performance23[0] + performance24[0] + performance25[0] + performance26[0] + performance27[0] + performance28[0] + performance29[0] + performance30[0])/30\n",
        "print(\"Loss Average: \", loss_avg)\n",
        "\n",
        "# Accuracy\n",
        "acc_avg =(performance1[1] + performance2[1] + performance3[1] + performance4[1] + performance5[1] + performance6[1] + performance7[1] + performance8[1] + performance9[1] + performance10[1]\n",
        "            + performance11[1] + performance12[1] + performance13[1] + performance14[1] + performance15[1] + performance16[1] + performance17[1] + performance18[1] + performance19[1] + performance20[1]\n",
        "            + performance21[1] + performance22[1] + performance23[1] + performance24[1] + performance25[1] + performance26[1] + performance27[1] + performance28[1] + performance29[1] + performance30[1])/30\n",
        "print(\"Accuraccy Average: \", acc_avg)\n",
        "\n",
        "# Precision\n",
        "precision_avg = (performance1[2] + performance2[2] + performance3[2] + performance4[2] + performance5[2] + performance6[2] + performance7[2] + performance8[2] + performance9[2] + performance10[2]\n",
        "            + performance11[2] + performance12[2] + performance13[2] + performance14[2] + performance15[2] + performance16[2] + performance17[2] + performance18[2] + performance19[2] + performance20[2]\n",
        "            + performance21[2] + performance22[2] + performance23[2] + performance24[2] + performance25[2] + performance26[2] + performance27[2] + performance28[2] + performance29[2] + performance30[2])/30\n",
        "print(\"Precision Average: \", precision_avg)\n",
        "\n",
        "# Recall\n",
        "recall_avg = (performance1[3] + performance2[3] + performance3[3] + performance4[3] + performance5[3] + performance6[3] + performance7[3] + performance8[3] + performance9[3] + performance10[3]\n",
        "            + performance11[3] + performance12[3] + performance13[3] + performance14[3] + performance15[3] + performance16[3] + performance17[3] + performance18[3] + performance19[3] + performance20[3]\n",
        "            + performance21[3] + performance22[3] + performance23[3] + performance24[3] + performance25[3] + performance26[3] + performance27[3] + performance28[3] + performance29[3] + performance30[3])/30\n",
        "print(\"Recall Average: \", recall_avg)\n",
        "\n",
        "# f1_metric\n",
        "f1_avg = (performance1[4] + performance2[4] + performance3[4] + performance4[4] + performance5[4] + performance6[4] + performance7[4] + performance8[4] + performance9[4] + performance10[4]\n",
        "            + performance11[4] + performance12[4] + performance13[4] + performance14[4] + performance15[4] + performance16[4] + performance17[4] + performance18[4] + performance19[4] + performance20[4]\n",
        "            + performance21[4] + performance22[4] + performance23[4] + performance24[4] + performance25[4] + performance26[4] + performance27[4] + performance28[4] + performance29[4] + performance30[4])/30\n",
        "print(\"F1 Average: \", f1_avg)\n",
        "\n",
        "auc_avg = (performance1[5] + performance2[5] + performance3[5] + performance4[5] + performance5[5] + performance6[5] + performance7[5] + performance8[5] + performance9[5] + performance10[5]\n",
        "            + performance11[5] + performance12[5] + performance13[5] + performance14[5] + performance15[5] + performance16[5] + performance17[5] + performance18[5] + performance19[5] + performance20[5]\n",
        "            + performance21[5] + performance22[5] + performance23[5] + performance24[5] + performance25[5] + performance26[5] + performance27[5] + performance28[5] + performance29[5] + performance30[5])/30\n",
        "print(\"AUC Average: \", auc_avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss Average:  0.6965337713559469\n",
            "Accuraccy Average:  0.30255404114723206\n",
            "Precision Average:  0.30303484201431274\n",
            "Recall Average:  1.0\n",
            "F1 Average:  0.45905670523643494\n",
            "AUC Average:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XuwAUg5_KOz4",
        "outputId": "1897a702-50ec-4b02-ea7c-c97ea577304b"
      },
      "source": [
        "#Take the standard deviation of the model samples\n",
        "\n",
        "#Loss SE\n",
        "Loss_SE = statistics.stdev([performance1[0], performance2[0], performance3[0], performance4[0], performance5[0],\n",
        "                  performance6[0], performance7[0], performance8[0], performance9[0], performance10[0],\n",
        "                  performance11[0], performance12[0], performance13[0], performance14[0], performance15[0],\n",
        "                  performance16[0], performance17[0], performance18[0], performance19[0], performance20[0], \n",
        "                  performance21[0], performance22[0], performance23[0], performance24[0], performance25[0],\n",
        "                  performance26[0], performance27[0], performance28[0], performance29[0], performance30[0]])\n",
        "print(\"Loss SE:\", Loss_SE)\n",
        "\n",
        "#Accuracy SE\n",
        "Acc_SE = statistics.stdev([performance1[1], performance2[1], performance3[1], performance4[1], performance5[1],\n",
        "                  performance6[1], performance7[1], performance8[1], performance9[1], performance10[1],\n",
        "                  performance11[1], performance12[1], performance13[1], performance14[1], performance15[1],\n",
        "                  performance16[1], performance17[1], performance18[1], performance19[1], performance20[1], \n",
        "                  performance21[1], performance22[1], performance23[1], performance24[1], performance25[1],\n",
        "                  performance26[1], performance27[1], performance28[1], performance29[1], performance30[1]])\n",
        "print(\"Accuraccy SE: \", Acc_SE)\n",
        "\n",
        "#Precision SE\n",
        "precision_SE = statistics.stdev([performance1[2], performance2[2], performance3[2], performance4[2], performance5[2],\n",
        "                  performance6[2], performance7[2], performance8[2], performance9[2], performance10[2],\n",
        "                  performance11[2], performance12[2], performance13[2], performance14[2], performance15[2],\n",
        "                  performance16[2], performance17[2], performance18[2], performance19[2], performance20[2], \n",
        "                  performance21[2], performance22[2], performance23[2], performance24[2], performance25[2],\n",
        "                  performance26[2], performance27[2], performance28[2], performance29[2], performance30[2]])\n",
        "print(\"Precision SE: \", precision_SE)\n",
        "\n",
        "#Recall \n",
        "Recall_SE = statistics.stdev([performance1[3], performance2[3], performance3[3], performance4[3], performance5[3],\n",
        "                  performance6[3], performance7[3], performance8[3], performance9[3], performance10[3],\n",
        "                  performance11[3], performance12[3], performance13[3], performance14[3], performance15[3],\n",
        "                  performance16[3], performance17[3], performance18[3], performance19[3], performance20[3], \n",
        "                  performance21[3], performance22[3], performance23[3], performance24[3], performance25[3],\n",
        "                  performance26[3], performance27[3], performance28[3], performance29[3], performance30[3]])\n",
        "print(\"Recall SE: \", Recall_SE)\n",
        "\n",
        "#F1 Score\n",
        "F1_Score_SE = statistics.stdev([performance1[4], performance2[4], performance3[4], performance4[4], performance5[4],\n",
        "                  performance6[4], performance7[4], performance8[4], performance9[4], performance10[4],\n",
        "                  performance11[4], performance12[4], performance13[4], performance14[4], performance15[4],\n",
        "                  performance16[4], performance17[4], performance18[4], performance19[4], performance20[4], \n",
        "                  performance21[4], performance22[4], performance23[4], performance24[4], performance25[4],\n",
        "                  performance26[4], performance27[4], performance28[4], performance29[4], performance30[4]])\n",
        "print(\"F1_Score_SE: \", F1_Score_SE)\n",
        "\n",
        "\n",
        "#AUC \n",
        "AUC_SE = statistics.stdev([performance1[5], performance2[5], performance3[5], performance4[5], performance5[5] , performance6[5], performance7[5], performance8[5], performance9[5], performance10[5], \n",
        "           performance11[5], performance12[5],performance13[5],performance14[5], performance15[5], performance16[5], performance17[5], performance18[5], performance19[5], performance20[5],\n",
        "           performance21[5], performance22[5], performance23[5], performance24[5], performance25[5], performance26[5], performance27[5], performance28[5], performance29[5], performance30[5]])\n",
        "print(\"AUC SE: \", AUC_SE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss SE: 0.0015223629855242178\n",
            "Accuraccy SE:  0.0\n",
            "Precision SE:  0.0\n",
            "Recall SE:  0.0\n",
            "F1_Score_SE:  0.0\n",
            "AUC SE:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aMpLKJ4OKt-X",
        "outputId": "83412763-6297-405f-f1be-98338e23ca4c"
      },
      "source": [
        "#Tensorflow Graphics\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}